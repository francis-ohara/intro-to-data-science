{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 2\n",
    "**Name**: Francis O'Hara Aidoo\n",
    "**Roll Number**: 10201100101 <br>\n",
    "\n",
    "Task: Solve all practice questions from the following webpages:\n",
    "\n",
    "1.https://pythonbasics.org/pandas-dataframe/\n",
    "\n",
    "1.1 https://data36.com/pandas-tutorial-1-basics-reading-data-files-dataframes-data-selection/\n",
    "\n",
    "2.https://www.tutorialspoint.com/python_pandas/python_pandas_dataframe.htm\n",
    "3.https://www.learndatasci.com/tutorials/python-pandas-tutorial-complete-introduction-for-beginners/   (different sources)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Website 1 Solutions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Creating n x 1 Dataframe from List\n",
    "The following code creates an n x 1 dataframe from a list containing n elements."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0\n",
      "0       Banana\n",
      "1        Apple\n",
      "2        Guava\n",
      "3  Straw berry\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fruits = [\"Banana\", \"Apple\", \"Guava\", \"Straw berry\"]\n",
    "fruits_df = pd.DataFrame(fruits)\n",
    "\n",
    "print(fruits_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating m x n Dataframe from List\n",
    "The following code creates an m x n dataframe from a list of m lists each of length n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Name  Score Grade\n",
      "0   Anna Tetteh     88    B2\n",
      "1  Eugene Stark     54    D7\n",
      "2    Helen Troy    100   A1+\n",
      "3  Bruce Banner     92    A1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "grades = [[\"Anna Tetteh\", 88, \"B2\"], [\"Eugene Stark\", 54, \"D7\"], [\"Helen Troy\", 100, \"A1+\"], [\"Bruce Banner\", 92, \"A1\"]]\n",
    "column_labels = [\"Name\", \"Score\", \"Grade\"]\n",
    "grades_df = pd.DataFrame(grades, columns=column_labels)\n",
    "print(grades_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Selecting column from a DataFrame by column name\n",
    "The following code selects the Name column from the grades_df DataFrame we created in the previous cell."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Anna Tetteh\n",
      "1    Eugene Stark\n",
      "2      Helen Troy\n",
      "3    Bruce Banner\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "names = grades_df[\"Name\"]\n",
    "print(names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Adding columns to an existing DataFrame\n",
    "The following code adds a column from a newly created DataFrame to an existing DataFrame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Before-Addition------------------\n",
      "           Name  Score Grade\n",
      "0   Anna Tetteh     88    B2\n",
      "1  Eugene Stark     54    D7\n",
      "2    Helen Troy    100   A1+\n",
      "3  Bruce Banner     92    A1\n",
      "-----------------After-Addition-------------------\n",
      "           Name  Score Grade                  Course\n",
      "0   Anna Tetteh     88    B2  Information Technology\n",
      "1  Eugene Stark     54    D7        Computer Science\n",
      "2    Helen Troy    100   A1+    Computer Engineering\n",
      "3  Bruce Banner     92    A1                Business\n"
     ]
    }
   ],
   "source": [
    "# Grades_df before addition of DataFrame\n",
    "print(\"----------------Before-Addition------------------\")\n",
    "print(grades_df)\n",
    "\n",
    "courses_df = pd.DataFrame([\"Information Technology\", \"Computer Science\", \"Computer Engineering\", \"Business\"], columns=[\"Course\"]) # New DataFrame\n",
    "grades_df[\"Course\"] = courses_df[\"Course\"]\n",
    "\n",
    "# Grades_df after addition of DataFrame\n",
    "print(\"-----------------After-Addition-------------------\")\n",
    "print(grades_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deleting columns\n",
    "The following code snippet deletes the Course column from grades_df using the <em>del</em> Python keyword"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Before-Deletion-------------------\n",
      "           Name  Score Grade                  Course\n",
      "0   Anna Tetteh     88    B2  Information Technology\n",
      "1  Eugene Stark     54    D7        Computer Science\n",
      "2    Helen Troy    100   A1+    Computer Engineering\n",
      "3  Bruce Banner     92    A1                Business\n",
      "-----------------After-Deletion-------------------\n",
      "           Name  Score Grade\n",
      "0   Anna Tetteh     88    B2\n",
      "1  Eugene Stark     54    D7\n",
      "2    Helen Troy    100   A1+\n",
      "3  Bruce Banner     92    A1\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------Before-Deletion-------------------\")\n",
    "print(grades_df)\n",
    "del grades_df[\"Course\"]\n",
    "print(\"-----------------After-Deletion-------------------\")\n",
    "print(grades_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Selecting single rows from data frame using .loc method\n",
    "The following code snippet selects the third row from the grades_df data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name     Helen Troy\n",
      "Score           100\n",
      "Grade           A1+\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "row3 = grades_df.loc[2]\n",
    "print(row3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Selecting single rows from data frame using .iloc method\n",
    "The following code snippet selects the 2nd row from the grades_df data frame using the .iloc data frame method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name     Eugene Stark\n",
      "Score              54\n",
      "Grade              D7\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "row2 = grades_df.iloc[1]\n",
    "print(row2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Appending rows to a data frame\n",
    "The following code snippet appends rows from a new ddta frame into the grades_df data frame using pd.concat() method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Before-Append-------------------\n",
      "           Name  Score Grade\n",
      "0   Anna Tetteh     88    B2\n",
      "1  Eugene Stark     54    D7\n",
      "2    Helen Troy    100   A1+\n",
      "3  Bruce Banner     92    A1\n",
      "-----------------After-Append-------------------\n",
      "               Name  Score Grade\n",
      "0       Anna Tetteh     88    B2\n",
      "1      Eugene Stark     54    D7\n",
      "2        Helen Troy    100   A1+\n",
      "3      Bruce Banner     92    A1\n",
      "4  Bertholdt Hoover     87    C3\n",
      "5      Armin Arlelt    100  A1++\n",
      "6      Pieck Finger     95    A1\n"
     ]
    }
   ],
   "source": [
    "new_df = pd.DataFrame([[\"Bertholdt Hoover\", 87, \"C3\"], [\"Armin Arlelt\", 100, \"A1++\"], [\"Pieck Finger\", 95, \"A1\"]], columns=[\"Name\", \"Score\", \"Grade\"])\n",
    "\n",
    "print(\"-----------------Before-Append-------------------\")\n",
    "print(grades_df)\n",
    "grades_df = pd.concat((grades_df, new_df), ignore_index=True)\n",
    "\n",
    "print(\"-----------------After-Append-------------------\")\n",
    "print(grades_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deleting single rows from a data frame\n",
    "The following code snippet deletes a single row from the data frame using the .drop() data frame method"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Before-deletion-------------------\n",
      "               Name  Score Grade\n",
      "0       Anna Tetteh     88    B2\n",
      "1      Eugene Stark     54    D7\n",
      "2        Helen Troy    100   A1+\n",
      "3      Bruce Banner     92    A1\n",
      "4  Bertholdt Hoover     87    C3\n",
      "5      Armin Arlelt    100  A1++\n",
      "6      Pieck Finger     95    A1\n",
      "-----------------After-deletion-------------------\n",
      "               Name  Score Grade\n",
      "0       Anna Tetteh     88    B2\n",
      "2        Helen Troy    100   A1+\n",
      "3      Bruce Banner     92    A1\n",
      "4  Bertholdt Hoover     87    C3\n",
      "5      Armin Arlelt    100  A1++\n",
      "6      Pieck Finger     95    A1\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------Before-deletion-------------------\")\n",
    "print(grades_df)\n",
    "\n",
    "grades_df = grades_df.drop(1)\n",
    "\n",
    "print(\"-----------------After-deletion-------------------\")\n",
    "print(grades_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a data frame from a dictionary\n",
    "The following code snippet creates a data frame from a python dictionary."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID   first_name   last_name     team      country\n",
      "0  001      Michael      Asante    Alpha       Canada\n",
      "1  002      Gabriel          Io    Bravo          USA\n",
      "2  003  Evangelista    Neptunes  Charlie      Namibia\n",
      "3  004      Hillary          Yu    Delta  Philippines\n",
      "4  005        Sarah  Pennyworth     Echo    Greenland\n"
     ]
    }
   ],
   "source": [
    "dictionary = {\"ID\":[\"001\", \"002\", \"003\", \"004\", \"005\"], \"first_name\":[\"Michael\", \"Gabriel\", \"Evangelista\", \"Hillary\", \"Sarah\"], \"last_name\":[\"Asante\", \"Io\", \"Neptunes\", \"Yu\", \"Pennyworth\"], \"team\":[\"Alpha\", \"Bravo\", \"Charlie\", \"Delta\", \"Echo\"], \"country\":[\"Canada\", \"USA\", \"Namibia\", \"Philippines\", \"Greenland\"]}\n",
    "\n",
    "soldiers = pd.DataFrame(dictionary)\n",
    "\n",
    "print(soldiers)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a data frame from a numpy array\n",
    "The following code snippet defines a numpy array and instantiates a pandas data frame from it:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID   first_name   last_name     team      country\n",
      "0  001      Michael      Asante    Alpha      Country\n",
      "1  002      Gabriel          Io    Bravo          USA\n",
      "2  003  Evangelista    Neptunes  Charlie      Namibia\n",
      "3  004      Hillary          Yu    Delta  Philippines\n",
      "4  005        Sarah  Pennyworth     Echo    Greenland\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "numpy_array = np.array([[\"001\", \"Michael\", \"Asante\", \"Alpha\", \"Country\"], [\"002\", \"Gabriel\", \"Io\", \"Bravo\", \"USA\"], [\"003\", \"Evangelista\", \"Neptunes\", \"Charlie\", \"Namibia\"], [\"004\", \"Hillary\", \"Yu\", \"Delta\", \"Philippines\"], [\"005\", \"Sarah\", \"Pennyworth\", \"Echo\", \"Greenland\"]])\n",
    "\n",
    "new_df2 = pd.DataFrame(numpy_array, columns=[\"ID\", \"first_name\", \"last_name\", \"team\", \"country\"])\n",
    "\n",
    "print(new_df2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a data frame from an existing data frame\n",
    "The following code snippet copies an existing data frame to create a new data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID   first_name   last_name     team      country\n",
      "0  001      Michael      Asante    Alpha      Country\n",
      "1  002      Gabriel          Io    Bravo          USA\n",
      "2  003  Evangelista    Neptunes  Charlie      Namibia\n",
      "3  004      Hillary          Yu    Delta  Philippines\n",
      "4  005        Sarah  Pennyworth     Echo    Greenland\n"
     ]
    }
   ],
   "source": [
    "new_df3 = new_df2.copy()\n",
    "print(new_df3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a data frame from a csv file\n",
    "The following code snippet creates a data frame by importing data from a csv file:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  first_name   last_name      team  country\n",
      "0   0      Gideon      Asante       Red    Ghana\n",
      "1   1      Dmitri   Dvocovich      Blue   Russia\n",
      "2   2    Francois    Arouette     Green   France\n",
      "3   3     Bradley      Cooper    Purple      USA\n",
      "4   4      Kratos      Athens   Crimson   Greece\n"
     ]
    }
   ],
   "source": [
    "new_df4 = pd.read_csv(\"C://users/franc/PycharmProjects/intro-to-data-science/data/data.csv\")\n",
    "print(new_df4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Website 2 Solutions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reading data from a csv file into a data frame in Pandas.\n",
    "The following code snippet reads data from a .csv file into a pandas data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id          item   price\n",
      "0   1         Apple    2.50\n",
      "1   2        Banana    4.50\n",
      "2   3   Straw Berry   10.00\n",
      "3   4     Pineapple    3.75\n",
      "4   5        Orange    8.00\n",
      "5   6       Coconut    7.50\n",
      "6   7         Mango   10.00\n",
      "7   8         Guava    7.50\n",
      "8   9         Grape    1.50\n"
     ]
    }
   ],
   "source": [
    "fruits = pd.read_csv(\"C://users/franc/PycharmProjects/intro-to-data-science/data/fruits.csv\", delimiter=\",\")\n",
    "print(fruits)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Website 2 Solutions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reading Data from a CSV file into a pandas data frame.\n",
    "The following code snippet reads data from a CSV file specified by the url into a pandas data frame and stores the result in the <em>data</em> variable."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2018-01-01 00:01:01  read  country_7  2458151261      SEO  North America\n",
      "0     2018-01-01 00:03:20  read  country_7  2458151262      SEO  South America\n",
      "1     2018-01-01 00:04:01  read  country_7  2458151263  AdWords         Africa\n",
      "2     2018-01-01 00:04:02  read  country_7  2458151264  AdWords         Europe\n",
      "3     2018-01-01 00:05:03  read  country_8  2458151265   Reddit  North America\n",
      "4     2018-01-01 00:05:42  read  country_6  2458151266   Reddit  North America\n",
      "...                   ...   ...        ...         ...      ...            ...\n",
      "1789  2018-01-01 23:57:14  read  country_2  2458153051  AdWords  North America\n",
      "1790  2018-01-01 23:58:33  read  country_8  2458153052      SEO           Asia\n",
      "1791  2018-01-01 23:59:36  read  country_6  2458153053   Reddit           Asia\n",
      "1792  2018-01-01 23:59:36  read  country_7  2458153054  AdWords         Europe\n",
      "1793  2018-01-01 23:59:38  read  country_5  2458153055   Reddit           Asia\n",
      "\n",
      "[1794 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"http://46.101.230.157/dilan/pandas_tutorial_read.csv\", delimiter=\";\")\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the above code snippet, no column labels are included in the csv file. The code snippet below reads the csv file and includes the appropriate column labels as an argument to the pd.read_csv() method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              my_datetime event    country     user_id   source          topic\n",
      "0     2018-01-01 00:01:01  read  country_7  2458151261      SEO  North America\n",
      "1     2018-01-01 00:03:20  read  country_7  2458151262      SEO  South America\n",
      "2     2018-01-01 00:04:01  read  country_7  2458151263  AdWords         Africa\n",
      "3     2018-01-01 00:04:02  read  country_7  2458151264  AdWords         Europe\n",
      "4     2018-01-01 00:05:03  read  country_8  2458151265   Reddit  North America\n",
      "...                   ...   ...        ...         ...      ...            ...\n",
      "1790  2018-01-01 23:57:14  read  country_2  2458153051  AdWords  North America\n",
      "1791  2018-01-01 23:58:33  read  country_8  2458153052      SEO           Asia\n",
      "1792  2018-01-01 23:59:36  read  country_6  2458153053   Reddit           Asia\n",
      "1793  2018-01-01 23:59:36  read  country_7  2458153054  AdWords         Europe\n",
      "1794  2018-01-01 23:59:38  read  country_5  2458153055   Reddit           Asia\n",
      "\n",
      "[1795 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"http://46.101.230.157/dilan/pandas_tutorial_read.csv\", delimiter=\";\", names=['my_datetime', 'event', 'country', 'user_id', 'source', 'topic'])\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Displaying a sample of your data frame.\n",
    "The following code snippet uses the head() data frame method to display the first 10 observations in the data set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           my_datetime event    country     user_id   source          topic\n",
      "0  2018-01-01 00:01:01  read  country_7  2458151261      SEO  North America\n",
      "1  2018-01-01 00:03:20  read  country_7  2458151262      SEO  South America\n",
      "2  2018-01-01 00:04:01  read  country_7  2458151263  AdWords         Africa\n",
      "3  2018-01-01 00:04:02  read  country_7  2458151264  AdWords         Europe\n",
      "4  2018-01-01 00:05:03  read  country_8  2458151265   Reddit  North America\n",
      "5  2018-01-01 00:05:42  read  country_6  2458151266   Reddit  North America\n",
      "6  2018-01-01 00:06:06  read  country_2  2458151267   Reddit         Europe\n",
      "7  2018-01-01 00:06:15  read  country_6  2458151268  AdWords         Europe\n",
      "8  2018-01-01 00:07:21  read  country_7  2458151269  AdWords  North America\n",
      "9  2018-01-01 00:07:29  read  country_5  2458151270   Reddit  North America\n"
     ]
    }
   ],
   "source": [
    "print(data.head(10))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet uses the tail() data frame method to display the last 10 observations in the data set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              my_datetime event    country     user_id   source          topic\n",
      "1785  2018-01-01 23:54:26  read  country_2  2458153046  AdWords         Africa\n",
      "1786  2018-01-01 23:54:39  read  country_6  2458153047   Reddit           Asia\n",
      "1787  2018-01-01 23:54:45  read  country_2  2458153048   Reddit           Asia\n",
      "1788  2018-01-01 23:55:04  read  country_7  2458153049  AdWords         Europe\n",
      "1789  2018-01-01 23:56:42  read  country_4  2458153050  AdWords           Asia\n",
      "1790  2018-01-01 23:57:14  read  country_2  2458153051  AdWords  North America\n",
      "1791  2018-01-01 23:58:33  read  country_8  2458153052      SEO           Asia\n",
      "1792  2018-01-01 23:59:36  read  country_6  2458153053   Reddit           Asia\n",
      "1793  2018-01-01 23:59:36  read  country_7  2458153054  AdWords         Europe\n",
      "1794  2018-01-01 23:59:38  read  country_5  2458153055   Reddit           Asia\n"
     ]
    }
   ],
   "source": [
    "print(data.tail(10))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet on the other hand displays 10 random observations from our data set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              my_datetime event    country     user_id   source          topic\n",
      "680   2018-01-01 09:20:32  read  country_7  2458151941  AdWords         Europe\n",
      "416   2018-01-01 05:44:15  read  country_7  2458151677   Reddit  North America\n",
      "1713  2018-01-01 23:04:51  read  country_5  2458152974   Reddit  South America\n",
      "76    2018-01-01 01:10:48  read  country_7  2458151337   Reddit           Asia\n",
      "12    2018-01-01 00:09:11  read  country_5  2458151273   Reddit           Asia\n",
      "541   2018-01-01 07:25:55  read  country_2  2458151802  AdWords  South America\n",
      "976   2018-01-01 13:04:28  read  country_6  2458152237      SEO         Europe\n",
      "1067  2018-01-01 14:27:12  read  country_7  2458152328   Reddit  South America\n",
      "215   2018-01-01 03:02:32  read  country_2  2458151476   Reddit           Asia\n",
      "1192  2018-01-01 16:09:33  read  country_5  2458152453      SEO  North America\n"
     ]
    }
   ],
   "source": [
    "print(data.sample(10))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Selecting Specific columns from the data frame\n",
    "The following code snippet selects specific features from our data set using square bracket notation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        country          topic\n",
      "0     country_7  North America\n",
      "1     country_7  South America\n",
      "2     country_7         Africa\n",
      "3     country_7         Europe\n",
      "4     country_8  North America\n",
      "...         ...            ...\n",
      "1790  country_2  North America\n",
      "1791  country_8           Asia\n",
      "1792  country_6           Asia\n",
      "1793  country_7         Europe\n",
      "1794  country_5           Asia\n",
      "\n",
      "[1795 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Selecting the country and topic columns only.\n",
    "sub_data = data[[\"country\", \"topic\"]]\n",
    "print(sub_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet selects a single feature from our data set using dot notation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       country_7\n",
      "1       country_7\n",
      "2       country_7\n",
      "3       country_7\n",
      "4       country_8\n",
      "          ...    \n",
      "1790    country_2\n",
      "1791    country_8\n",
      "1792    country_6\n",
      "1793    country_7\n",
      "1794    country_5\n",
      "Name: country, Length: 1795, dtype: object\n"
     ]
    }
   ],
   "source": [
    "sub_data = data.country\n",
    "print(sub_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Filtering specific observations from the data frame\n",
    "The following code snippet filters the data frame, selecting only those data frames where the source feature has a value of SEO."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              my_datetime event    country     user_id source          topic\n",
      "0     2018-01-01 00:01:01  read  country_7  2458151261    SEO  North America\n",
      "1     2018-01-01 00:03:20  read  country_7  2458151262    SEO  South America\n",
      "11    2018-01-01 00:08:57  read  country_7  2458151272    SEO      Australia\n",
      "15    2018-01-01 00:11:22  read  country_7  2458151276    SEO  North America\n",
      "16    2018-01-01 00:13:05  read  country_8  2458151277    SEO  North America\n",
      "...                   ...   ...        ...         ...    ...            ...\n",
      "1772  2018-01-01 23:45:58  read  country_7  2458153033    SEO  South America\n",
      "1777  2018-01-01 23:49:52  read  country_5  2458153038    SEO  North America\n",
      "1779  2018-01-01 23:51:25  read  country_4  2458153040    SEO  South America\n",
      "1784  2018-01-01 23:54:03  read  country_2  2458153045    SEO  North America\n",
      "1791  2018-01-01 23:58:33  read  country_8  2458153052    SEO           Asia\n",
      "\n",
      "[346 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "sub_data = data[data.source==\"SEO\"]\n",
    "print(sub_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combining Pandas methods and operators\n",
    "The following code snippet selects the first five observations using the head() method, and selects only the country and source features using the square bracket syntax."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     country   source\n",
      "0  country_7      SEO\n",
      "1  country_7      SEO\n",
      "2  country_7  AdWords\n",
      "3  country_7  AdWords\n",
      "4  country_8   Reddit\n"
     ]
    }
   ],
   "source": [
    "sub_data = data.head(5)[[\"country\", \"source\"]]\n",
    "print(sub_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet selects the country and source features from the data set first and then selects the first five observations using the head() method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     country   source\n",
      "0  country_7      SEO\n",
      "1  country_7      SEO\n",
      "2  country_7  AdWords\n",
      "3  country_7  AdWords\n",
      "4  country_8   Reddit\n"
     ]
    }
   ],
   "source": [
    "sub_data = data[[\"country\", \"source\"]].head(5)\n",
    "print(sub_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pandas Tutorial Challenge\n",
    "Select the user_id, the country and the topic columns for the users who are from country_2! Print the first five rows only!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id    country   topic\n",
      "6   2458151267  country_2  Europe\n",
      "13  2458151274  country_2  Europe\n",
      "17  2458151278  country_2    Asia\n",
      "19  2458151280  country_2    Asia\n",
      "20  2458151281  country_2    Asia\n"
     ]
    }
   ],
   "source": [
    "sub_data = data[data.country==\"country_2\"][[\"user_id\", \"country\", \"topic\"]].head()\n",
    "print(sub_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Website 3 Solutions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating an empty pandas data frame\n",
    "The following code snippet creates an empty data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a data frame from a list\n",
    "The following code snippet creates a one-dimensional data frame from a list."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name\n",
      "0     Google\n",
      "1  Bloomberg\n",
      "2       Meta\n",
      "3      Apple\n",
      "4      Tesla\n"
     ]
    }
   ],
   "source": [
    "data = [\"Google\", \"Bloomberg\", \"Meta\", \"Apple\", \"Tesla\"] # the list\n",
    "df = pd.DataFrame(data, columns=[\"name\"])\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet creates a multidimensional data frame from a list of lists."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name    market cap\n",
      "0     Google  1.270000e+12\n",
      "1  Bloomberg  1.230000e+11\n",
      "2       Meta  3.429000e+11\n",
      "3      Apple  2.230000e+12\n",
      "4      Tesla  6.499900e+11\n"
     ]
    }
   ],
   "source": [
    "data = [[\"Google\", 1.27e12], [\"Bloomberg\", 123e9], [\"Meta\", 342.9e9], [\"Apple\", 2.23e12], [\"Tesla\", 649.99e9]] # the list\n",
    "df = pd.DataFrame(data, columns=[\"name\", \"market cap\"])\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet creates a multidimensional data frame from a list of dictionaries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name    market cap\n",
      "0     Google  1.270000e+12\n",
      "1  Bloomberg  1.230000e+09\n",
      "2       Meta  3.429000e+11\n",
      "3      Apple  2.230000e+12\n",
      "4      Tesla  6.499900e+11\n"
     ]
    }
   ],
   "source": [
    "data = [{\"name\": \"Google\",\"market cap\": 1.27e12}, {\"name\":\"Bloomberg\", \"market cap\": 1.23e9}, {\"name\":\"Meta\", \"market cap\":3.429e11}, {\"name\": \"Apple\", \"market cap\": 2.23e12}, {\"name\": \"Tesla\", \"market cap\": 6.4999e11}]\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a data frame from a dictionary\n",
    "The following code snippet creates a data frame from a dictionary.\n",
    "NB: The keys of the dictionary become feature labels and the values become observations for the corresponding feature."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Age\n",
      "0    Tom   28\n",
      "1   Jack   34\n",
      "2  Steve   29\n",
      "3  Ricky   42\n"
     ]
    }
   ],
   "source": [
    "data = {'Name':['Tom', 'Jack', 'Steve', 'Ricky'],'Age':[28,34,29,42]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the above snippet, the rows of the data frame are numbered from 0 to n-1 by default, where n is the numbber of observations in the data frame.\n",
    "In the code snippet below, the index argument of the data frame constructor will be used to label the rows."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age\n",
      "A1    Tom   28\n",
      "A2   Jack   34\n",
      "A3  Steve   29\n",
      "A4  Ricky   42\n"
     ]
    }
   ],
   "source": [
    "data = {'Name':['Tom', 'Jack', 'Steve', 'Ricky'],'Age':[28,34,29,42]}\n",
    "df = pd.DataFrame(data, index=[\"A1\", \"A2\", \"A3\", \"A4\"])\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet creates a dataframe from a dictionary of pandas series."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name    market_cap\n",
      "0     Google  1.270000e+12\n",
      "1  Bloomberg  1.230000e+09\n",
      "2       Meta  3.429000e+11\n",
      "3      Apple  2.230000e+12\n",
      "4      Tesla  6.499900e+11\n"
     ]
    }
   ],
   "source": [
    "names = pd.Series([\"Google\", \"Bloomberg\", \"Meta\", \"Apple\", \"Tesla\"])\n",
    "market_caps = pd.Series([1.27e12, 1.23e9, 3.429e11, 2.23e12, 6.4999e11])\n",
    "data = {\"name\": names, \"market_cap\": market_caps}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Adding columns to a data frame\n",
    "The following code snippet adds a column to the df dataframe from a newly created data series."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name    market_cap  year_founded\n",
      "0     Google  1.270000e+12          1998\n",
      "1  Bloomberg  1.230000e+09          1981\n",
      "2       Meta  3.429000e+11          2004\n",
      "3      Apple  2.230000e+12          1976\n",
      "4      Tesla  6.499900e+11          2003\n"
     ]
    }
   ],
   "source": [
    "new_series = pd.Series([1998, 1981, 2004, 1976, 2003])\n",
    "df[\"year_founded\"] = new_series\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet adds a column to the df column from an existing data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name    market_cap  year_founded  random_factor\n",
      "0     Google  1.270000e+12          1998   6.356356e+08\n",
      "1  Bloomberg  1.230000e+09          1981   6.208985e+05\n",
      "2       Meta  3.429000e+11          2004   1.711078e+08\n",
      "3      Apple  2.230000e+12          1976   1.128543e+09\n",
      "4      Tesla  6.499900e+11          2003   3.245082e+08\n"
     ]
    }
   ],
   "source": [
    "df2 = df\n",
    "df[\"random_factor\"] = df[\"market_cap\"] / df[\"year_founded\"]\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deleting columns from a data frame\n",
    "The following code snippet deletes a column from the data frame using the del python keyword."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------before-deletion--------\n",
      "        name    market_cap  year_founded  random_factor\n",
      "0     Google  1.270000e+12          1998   6.356356e+08\n",
      "1  Bloomberg  1.230000e+09          1981   6.208985e+05\n",
      "2       Meta  3.429000e+11          2004   1.711078e+08\n",
      "3      Apple  2.230000e+12          1976   1.128543e+09\n",
      "4      Tesla  6.499900e+11          2003   3.245082e+08\n",
      "--------after-deletion---------\n",
      "        name    market_cap  year_founded\n",
      "0     Google  1.270000e+12          1998\n",
      "1  Bloomberg  1.230000e+09          1981\n",
      "2       Meta  3.429000e+11          2004\n",
      "3      Apple  2.230000e+12          1976\n",
      "4      Tesla  6.499900e+11          2003\n"
     ]
    }
   ],
   "source": [
    "print(\"-------before-deletion--------\")\n",
    "print(df)\n",
    "\n",
    "# deletion\n",
    "copy = df[\"random_factor\"] # creating a copy of column to be deleted.\n",
    "\n",
    "del df[\"random_factor\"]\n",
    "\n",
    "print(\"--------after-deletion---------\")\n",
    "print(df)\n",
    "df[\"random_factor\"] = copy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet deletes a column from the data frame using the data frame pop() method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------before-deletion--------\n",
      "        name    market_cap  year_founded  random_factor\n",
      "0     Google  1.270000e+12          1998   6.356356e+08\n",
      "1  Bloomberg  1.230000e+09          1981   6.208985e+05\n",
      "2       Meta  3.429000e+11          2004   1.711078e+08\n",
      "3      Apple  2.230000e+12          1976   1.128543e+09\n",
      "4      Tesla  6.499900e+11          2003   3.245082e+08\n",
      "--------after-deletion---------\n",
      "        name    market_cap  year_founded\n",
      "0     Google  1.270000e+12          1998\n",
      "1  Bloomberg  1.230000e+09          1981\n",
      "2       Meta  3.429000e+11          2004\n",
      "3      Apple  2.230000e+12          1976\n",
      "4      Tesla  6.499900e+11          2003\n"
     ]
    }
   ],
   "source": [
    "print(\"-------before-deletion--------\")\n",
    "print(df)\n",
    "\n",
    "df.pop(\"random_factor\")\n",
    "\n",
    "print(\"--------after-deletion---------\")\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Selecting rows and columns from a data frame with loc\n",
    "The following code snippets selects the name and year_founded columns as well as the 0th, 2nd, and 4th row from the df data frame using loc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name  year_founded\n",
      "0  Google          1998\n",
      "2    Meta          2004\n",
      "4   Tesla          2003\n"
     ]
    }
   ],
   "source": [
    "selection = df.loc[[0,2,4], [\"name\", \"year_founded\"]]\n",
    "print(selection)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet performs the above selection using iloc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name  year_founded\n",
      "0  Google          1998\n",
      "2    Meta          2004\n",
      "4   Tesla          2003\n"
     ]
    }
   ],
   "source": [
    "selection = df.iloc[[0, 2, 4], [0, 2]]\n",
    "print(selection)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet selects a range of rows and columns from the df data frame using slicing.\n",
    "NB: For iloc, stop index of the slice is exclusive, but for loc, both start and stop index of the slice are inclusive."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     market_cap  year_founded\n",
      "0  1.270000e+12          1998\n",
      "1  1.230000e+09          1981\n"
     ]
    }
   ],
   "source": [
    "selection = df.iloc[0:2, 1:3]\n",
    "print(selection)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deleting rows from a data frame\n",
    "Just as columns are deleted from a data frame using the del keyword and .pop method, Rows can be deleted using the del keyword and the .drop method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet deletes the 3rd column from the df data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Before-deletion---------\n",
      "        name    market_cap  year_founded\n",
      "0     Google  1.270000e+12          1998\n",
      "1  Bloomberg  1.230000e+09          1981\n",
      "2       Meta  3.429000e+11          2004\n",
      "3      Apple  2.230000e+12          1976\n",
      "4      Tesla  6.499900e+11          2003\n",
      "---------After-deletion--------\n",
      "        name    market_cap  year_founded\n",
      "0     Google  1.270000e+12          1998\n",
      "1  Bloomberg  1.230000e+09          1981\n",
      "3      Apple  2.230000e+12          1976\n",
      "4      Tesla  6.499900e+11          2003\n"
     ]
    }
   ],
   "source": [
    "print(\"--------Before-deletion---------\")\n",
    "print(df)\n",
    "\n",
    "df = df.drop(2)\n",
    "\n",
    "print(\"---------After-deletion--------\")\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Website 4 Solutions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a data frame from scratch (using a dictionary)\n",
    "The following code snippet creates a pandas data frame from scratch using the below dictionary."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   apples  oranges\n",
      "0       3        0\n",
      "1       2        3\n",
      "2       0        7\n",
      "3       1        2\n"
     ]
    }
   ],
   "source": [
    "data = {'apples': [3, 2, 0, 1], 'oranges': [0, 3, 7, 2]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet does the above, but includes row labels for the data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        apples  oranges\n",
      "June         3        0\n",
      "Robert       2        3\n",
      "Lily         0        7\n",
      "David        1        2\n"
     ]
    }
   ],
   "source": [
    "data = {'apples': [3, 2, 0, 1], 'oranges': [0, 3, 7, 2]}\n",
    "df = pd.DataFrame(data,index=[\"June\", \"Robert\", \"Lily\", \"David\"])\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the above data frame, each row represents a particular customer's order.\n",
    "### Selecting a single row\n",
    "In the code snippet below, a single row(custmer) is selected via the iloc method and row label."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apples     3\n",
      "oranges    0\n",
      "Name: June, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "selection = df.loc[\"June\"]\n",
    "print(selection)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reading data from a csv file\n",
    "The following code snippet demonstrates how to use the read_csv method to read csv files into a pandas data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        apples  oranges\n",
      "June         3        0\n",
      "Robert       2        3\n",
      "Lily         0        7\n",
      "David        1        2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"c://users/franc/PycharmProjects/intro-to-data-science/data/purchases.csv\", delimiter=\",\", index_col=0)\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reading data from a json file\n",
    "The following code snippet reads the purchases data from a json file instead via the read_json method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           apples  oranges\n",
      "0   David       3        0\n",
      "1    June       2        3\n",
      "2    Lily       0        7\n",
      "3  Robert       1        2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"C:/users/franc/PycharmProjects/intro-to-data-science/data/purchases.json\")\n",
    "print(df)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reading data from an sql database.\n",
    "Pandas can read tables stored inside a relational database and store them as data frames.\n",
    "The following code snippets demonstrates how to read data into a pandas data frame from an sql database. <br>\n",
    "For the purposes of this tutorial, we'll be making use of the sqlite database which stores databases as a single file with the extension .db from which we can read data similar to how we would read data from a csv file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We first need to install <strong>pysqlite3</strong> which is a database driver that allows python programs to interact with sqlite databases using the following command:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pysqlite3\n",
      "  Using cached pysqlite3-0.4.7.tar.gz (40 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: pysqlite3\n",
      "  Building wheel for pysqlite3 (setup.py): started\n",
      "  Building wheel for pysqlite3 (setup.py): finished with status 'done'\n",
      "  Running setup.py clean for pysqlite3\n",
      "Failed to build pysqlite3\n",
      "Installing collected packages: pysqlite3\n",
      "  Running setup.py install for pysqlite3: started\n",
      "  Running setup.py install for pysqlite3: finished with status 'done'\n",
      "Successfully installed pysqlite3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Legacy build of wheel for 'pysqlite3' created no files.\n",
      "  Command arguments: 'C:\\Users\\franc\\anaconda3\\envs\\intro-to-data-science\\python.exe' -u -c '\n",
      "  exec(compile('\"'\"''\"'\"''\"'\"'\n",
      "  # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py\n",
      "  #\n",
      "  # - It imports setuptools before invoking setup.py, to enable projects that directly\n",
      "  #   import from `distutils.core` to work with newer packaging standards.\n",
      "  # - It provides a clear error message when setuptools is not installed.\n",
      "  # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so\n",
      "  #   setuptools doesn'\"'\"'t think the script is `-c`. This avoids the following warning:\n",
      "  #     manifest_maker: standard file '\"'\"'-c'\"'\"' not found\".\n",
      "  # - It generates a shim setup.py, for handling setup.cfg-only projects.\n",
      "  import os, sys, tokenize\n",
      "  \n",
      "  try:\n",
      "      import setuptools\n",
      "  except ImportError as error:\n",
      "      print(\n",
      "          \"ERROR: Can not execute `setup.py` since setuptools is not available in \"\n",
      "          \"the build environment.\",\n",
      "          file=sys.stderr,\n",
      "      )\n",
      "      sys.exit(1)\n",
      "  \n",
      "  __file__ = %r\n",
      "  sys.argv[0] = __file__\n",
      "  \n",
      "  if os.path.exists(__file__):\n",
      "      filename = __file__\n",
      "      with tokenize.open(__file__) as f:\n",
      "          setup_py_code = f.read()\n",
      "  else:\n",
      "      filename = \"<auto-generated setuptools caller>\"\n",
      "      setup_py_code = \"from setuptools import setup; setup()\"\n",
      "  \n",
      "  exec(compile(setup_py_code, filename, \"exec\"))\n",
      "  '\"'\"''\"'\"''\"'\"' % ('\"'\"'C:\\\\Users\\\\franc\\\\AppData\\\\Local\\\\Temp\\\\pip-install-lqhxtueg\\\\pysqlite3_23830ea6647c4cdc9cb04770966928b3\\\\setup.py'\"'\"',), \"<pip-setuptools-caller>\", \"exec\"))' bdist_wheel -d 'C:\\Users\\franc\\AppData\\Local\\Temp\\pip-wheel-w9bcxg00'\n",
      "  Command output: [use --verbose to show]\n"
     ]
    }
   ],
   "source": [
    "!pip install pysqlite3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we have to create a connection to our sqlite database using the connect method of the sqlite3 driver."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "connection = sqlite3.connect(\"C:/users/franc/PycharmProjects/intro-to-data-science/data/data.db\")\n",
    "# connection is now a database connection object we can use to access data stored in the data.db database."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following command uses the read_sql_query() method to query the data.db database through our connection object, and read the resulting table as a pandas data frame which we store in the variable df."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index  apples  oranges\n",
      "0    June       3        0\n",
      "1  Robert       2        3\n",
      "2    Lily       0        7\n",
      "3   David       1        2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM purchases\", connection)\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We failed to state that the index column of the purchases table in our data.db database was to be treated as the index column. <br>\n",
    "But all hope is not lost as we can use the set_index() data frame method to set our index column."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        apples  oranges\n",
      "index                  \n",
      "June         3        0\n",
      "Robert       2        3\n",
      "Lily         0        7\n",
      "David        1        2\n"
     ]
    }
   ],
   "source": [
    "df = df.set_index(\"index\")\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Converting a pandas data frame into other formats.\n",
    "The following code snippet converts the df data frame into a **csv file** stored in the <em>output</em> sub-directory of our <em>data</em> directory."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/output/output_csv.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet converts the df data frame into a **json file** and stores it in the <em>output</em> sub-directory of the <em>data</em> directory."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "df.to_json(\"../data/output/output_json.json\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet converts the df data frame into an **sql table** and stores it in the data.db sqlite database via our connection object."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Table 'new purchases' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [52]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_sql\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mnew purchases\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconnection\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\intro-to-data-science\\lib\\site-packages\\pandas\\core\\generic.py:2951\u001B[0m, in \u001B[0;36mNDFrame.to_sql\u001B[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001B[0m\n\u001B[0;32m   2794\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2795\u001B[0m \u001B[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001B[39;00m\n\u001B[0;32m   2796\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2947\u001B[0m \u001B[38;5;124;03m[(1,), (None,), (2,)]\u001B[39;00m\n\u001B[0;32m   2948\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m  \u001B[38;5;66;03m# noqa:E501\u001B[39;00m\n\u001B[0;32m   2949\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mio\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m sql\n\u001B[1;32m-> 2951\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msql\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_sql\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2952\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2953\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2954\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcon\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2955\u001B[0m \u001B[43m    \u001B[49m\u001B[43mschema\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mschema\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2956\u001B[0m \u001B[43m    \u001B[49m\u001B[43mif_exists\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mif_exists\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2957\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2958\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2959\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunksize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2960\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2961\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2962\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\intro-to-data-science\\lib\\site-packages\\pandas\\io\\sql.py:698\u001B[0m, in \u001B[0;36mto_sql\u001B[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001B[0m\n\u001B[0;32m    693\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(frame, DataFrame):\n\u001B[0;32m    694\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[0;32m    695\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mframe\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m argument should be either a Series or a DataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    696\u001B[0m     )\n\u001B[1;32m--> 698\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pandas_sql\u001B[38;5;241m.\u001B[39mto_sql(\n\u001B[0;32m    699\u001B[0m     frame,\n\u001B[0;32m    700\u001B[0m     name,\n\u001B[0;32m    701\u001B[0m     if_exists\u001B[38;5;241m=\u001B[39mif_exists,\n\u001B[0;32m    702\u001B[0m     index\u001B[38;5;241m=\u001B[39mindex,\n\u001B[0;32m    703\u001B[0m     index_label\u001B[38;5;241m=\u001B[39mindex_label,\n\u001B[0;32m    704\u001B[0m     schema\u001B[38;5;241m=\u001B[39mschema,\n\u001B[0;32m    705\u001B[0m     chunksize\u001B[38;5;241m=\u001B[39mchunksize,\n\u001B[0;32m    706\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[0;32m    707\u001B[0m     method\u001B[38;5;241m=\u001B[39mmethod,\n\u001B[0;32m    708\u001B[0m     engine\u001B[38;5;241m=\u001B[39mengine,\n\u001B[0;32m    709\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mengine_kwargs,\n\u001B[0;32m    710\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\intro-to-data-science\\lib\\site-packages\\pandas\\io\\sql.py:2192\u001B[0m, in \u001B[0;36mSQLiteDatabase.to_sql\u001B[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, **kwargs)\u001B[0m\n\u001B[0;32m   2181\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcol\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmy_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) not a string\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   2183\u001B[0m table \u001B[38;5;241m=\u001B[39m SQLiteTable(\n\u001B[0;32m   2184\u001B[0m     name,\n\u001B[0;32m   2185\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2190\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[0;32m   2191\u001B[0m )\n\u001B[1;32m-> 2192\u001B[0m \u001B[43mtable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2193\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m table\u001B[38;5;241m.\u001B[39minsert(chunksize, method)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\intro-to-data-science\\lib\\site-packages\\pandas\\io\\sql.py:834\u001B[0m, in \u001B[0;36mSQLTable.create\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    832\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexists():\n\u001B[0;32m    833\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mif_exists \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfail\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 834\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTable \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m already exists.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    835\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mif_exists \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreplace\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    836\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpd_sql\u001B[38;5;241m.\u001B[39mdrop_table(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mschema)\n",
      "\u001B[1;31mValueError\u001B[0m: Table 'new purchases' already exists."
     ]
    }
   ],
   "source": [
    "df.to_sql(\"new purchases\", connection)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The following section covers some important data frame operations\n",
    "To demonstrate various operations that can be performed on a pandas database, we will be using a [movies data set](https://storage.googleapis.com/kagglesdsdata/datasets/516826/954748/df_movie_ratings.csv?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20221015%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20221015T113249Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=2736f429dbdfa2c10167ce36777a57e8f2874890ca7396cae864f32bdde4b06a2e1f872cec927266e26740a615c87eea111bb4e6f771c2b2d440bcdf6e22548ddafb32754312dd011087dafc8eb5bca0ecff86b3752e3b834498ba96327548216bf36d9d3a29e4243d95d3052c5abe1436b41027d40ab7743ae73f539b620b32473ddd71dd4e3f3e9a93e86b1fc24a02286786f8004719a68e0fb720b0d76b0c1194d21b241d91e96ae5eb345c9d4393b3a98a5742754d6a6739349a994d4cfb59a51dc308e10c9f6ebd2a9123968af54150de38e149c2318b9a9226607c003f2a7bcdc9f30cc1b4e98c0083f5c84f54e8663bbdcf1e80d672d60ff737a49c53) we downloaded from kaggle."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0                                       movie  year  imdb  \\\n",
      "0              0                                   Gladiator  2000   8.5   \n",
      "1              1                                     Memento  2000   8.4   \n",
      "2              2                                      Snatch  2000   8.3   \n",
      "3              3                         Requiem for a Dream  2000   8.3   \n",
      "4              4                                       X-Men  2000   7.4   \n",
      "...          ...                                         ...   ...   ...   \n",
      "3611        3611                             Triple Frontier  2019   6.4   \n",
      "3612        3612  How to Train Your Dragon: The Hidden World  2019   7.5   \n",
      "3613        3613                 Men in Black: International  2019   5.6   \n",
      "3614        3614                      Zombieland: Double Tap  2019   6.8   \n",
      "3615        3615                              Murder Mystery  2019   6.0   \n",
      "\n",
      "      metascore    votes                                   genre  runtime  \\\n",
      "0            67  1265139      ['Action', ' Adventure', ' Drama']  155 min   \n",
      "1            80  1065249                ['Mystery', ' Thriller']  113 min   \n",
      "2            55   744029                    ['Comedy', ' Crime']  104 min   \n",
      "3            68   725875                               ['Drama']  102 min   \n",
      "4            64   550968     ['Action', ' Adventure', ' Sci-Fi']  104 min   \n",
      "...         ...      ...                                     ...      ...   \n",
      "3611         61    90756      ['Action', ' Adventure', ' Crime']  125 min   \n",
      "3612         71    87006  ['Animation', ' Action', ' Adventure']  104 min   \n",
      "3613         38    85672     ['Action', ' Adventure', ' Comedy']  114 min   \n",
      "3614         55    82913        ['Action', ' Comedy', ' Horror']   99 min   \n",
      "3615         38    81450         ['Action', ' Comedy', ' Crime']   97 min   \n",
      "\n",
      "            gross  n_imdb  \n",
      "0     187705427.0    85.0  \n",
      "1      25544867.0    84.0  \n",
      "2      30328156.0    83.0  \n",
      "3       3635482.0    83.0  \n",
      "4     157299717.0    74.0  \n",
      "...           ...     ...  \n",
      "3611          NaN    64.0  \n",
      "3612  160799505.0    75.0  \n",
      "3613   79800736.0    56.0  \n",
      "3614   26803104.0    68.0  \n",
      "3615          NaN    60.0  \n",
      "\n",
      "[3616 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# importing the movies data set from a csv file\n",
    "movies= pd.read_csv(\"../data/df_movie_ratings.csv\", delimiter=\",\")\n",
    "print(movies)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Viewing the data\n",
    "The following snippets cover various data frame methods that may be useful for viewing or analyzing the data stored in the data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Using the head() method to view first few observations in data frame:**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                   movie  year  imdb  metascore    votes  \\\n",
      "0           0               Gladiator  2000   8.5         67  1265139   \n",
      "1           1                 Memento  2000   8.4         80  1065249   \n",
      "2           2                  Snatch  2000   8.3         55   744029   \n",
      "3           3     Requiem for a Dream  2000   8.3         68   725875   \n",
      "4           4                   X-Men  2000   7.4         64   550968   \n",
      "5           5               Cast Away  2000   7.8         73   491129   \n",
      "6           6         American Psycho  2000   7.6         64   453294   \n",
      "7           7             Unbreakable  2000   7.3         62   370098   \n",
      "8           8  Mission: Impossible II  2000   6.1         59   299974   \n",
      "9           9        Meet the Parents  2000   7.0         73   299610   \n",
      "\n",
      "                                   genre  runtime        gross  n_imdb  \n",
      "0     ['Action', ' Adventure', ' Drama']  155 min  187705427.0    85.0  \n",
      "1               ['Mystery', ' Thriller']  113 min   25544867.0    84.0  \n",
      "2                   ['Comedy', ' Crime']  104 min   30328156.0    83.0  \n",
      "3                              ['Drama']  102 min    3635482.0    83.0  \n",
      "4    ['Action', ' Adventure', ' Sci-Fi']  104 min  157299717.0    74.0  \n",
      "5    ['Adventure', ' Drama', ' Romance']  143 min  233632142.0    78.0  \n",
      "6         ['Comedy', ' Crime', ' Drama']  101 min   15070285.0    76.0  \n",
      "7       ['Drama', ' Mystery', ' Sci-Fi']  106 min   95011339.0    73.0  \n",
      "8  ['Action', ' Adventure', ' Thriller']  123 min  215409889.0    61.0  \n",
      "9                 ['Comedy', ' Romance']  108 min  166244045.0    70.0  \n"
     ]
    }
   ],
   "source": [
    "data = movies.head(10) # Selects first 10 observations in data frame.\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Using the tail() method to view last few observations in data frame:**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0                        movie  year  imdb  metascore  votes  \\\n",
      "3613        3613  Men in Black: International  2019   5.6         38  85672   \n",
      "3614        3614       Zombieland: Double Tap  2019   6.8         55  82913   \n",
      "3615        3615               Murder Mystery  2019   6.0         38  81450   \n",
      "\n",
      "                                    genre  runtime       gross  n_imdb  \n",
      "3613  ['Action', ' Adventure', ' Comedy']  114 min  79800736.0    56.0  \n",
      "3614     ['Action', ' Comedy', ' Horror']   99 min  26803104.0    68.0  \n",
      "3615      ['Action', ' Comedy', ' Crime']   97 min         NaN    60.0  \n"
     ]
    }
   ],
   "source": [
    "data = movies.tail(3) # Selects last 3 observations in data frame.\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Using the info() method to obtain general information about data frame:**\n",
    "The info() method displays number of rows, columns, non-null values in each column, data type of values in each column, as well as overall memory usage of the data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3616 entries, 0 to 3615\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  3616 non-null   int64  \n",
      " 1   movie       3616 non-null   object \n",
      " 2   year        3616 non-null   int64  \n",
      " 3   imdb        3616 non-null   float64\n",
      " 4   metascore   3616 non-null   int64  \n",
      " 5   votes       3616 non-null   int64  \n",
      " 6   genre       3616 non-null   object \n",
      " 7   runtime     3616 non-null   object \n",
      " 8   gross       3536 non-null   float64\n",
      " 9   n_imdb      3616 non-null   float64\n",
      "dtypes: float64(3), int64(4), object(3)\n",
      "memory usage: 282.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(movies.info())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Using the describe() method to retrieve quantitative information about dataframe:**\n",
    "The describe() method can be used to retrieve the number of observations, average, standard deviation, maximum, minimum, 25th, 50th, and 75th percentile of the data in each column of a dataframe as follows:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0         year         imdb    metascore         votes  \\\n",
      "count  3616.000000  3616.000000  3616.000000  3616.000000  3.616000e+03   \n",
      "mean   1807.500000  2009.355088     7.114934    63.591814  3.275271e+05   \n",
      "std    1043.993614     5.756038     0.738934    15.675350  2.261506e+05   \n",
      "min       0.000000  2000.000000     4.100000    24.000000  8.145000e+04   \n",
      "25%     903.750000  2004.000000     6.600000    52.000000  1.874390e+05   \n",
      "50%    1807.500000  2009.000000     7.200000    64.000000  2.527240e+05   \n",
      "75%    2711.250000  2014.000000     7.700000    75.000000  3.997345e+05   \n",
      "max    3615.000000  2019.000000     9.000000   100.000000  2.173427e+06   \n",
      "\n",
      "              gross       n_imdb  \n",
      "count  3.536000e+03  3616.000000  \n",
      "mean   1.269317e+08    71.149336  \n",
      "std    1.175377e+08     7.389338  \n",
      "min    3.600000e+03    41.000000  \n",
      "25%    4.724575e+07    66.000000  \n",
      "50%    9.354176e+07    72.000000  \n",
      "75%    1.710725e+08    77.000000  \n",
      "max    9.366622e+08    90.000000  \n"
     ]
    }
   ],
   "source": [
    "print(movies.describe())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that all categorical variables had their columns ignored.\n",
    "But `describe()` can still give information about categorical variables as shown below:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count          3616\n",
      "unique          904\n",
      "top       Gladiator\n",
      "freq              4\n",
      "Name: movie, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(movies.movie.describe()) # Calls describe() method on categorical variable of the dataframe, movie."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the output, we can tell that the movie column has only 904 unique values, the most frequent movie title is \"Gladiator\", and it occurred 4 times in the movie column."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Using the shape attribute to determine number of rows and columns in data frame:**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3616, 10)\n",
      "No. of rows: 3616\n",
      "No. of columns: 10\n"
     ]
    }
   ],
   "source": [
    "shape = movies.shape\n",
    "print(shape)\n",
    "print(\"No. of rows:\", shape[0])\n",
    "print(\"No. of columns:\", shape[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Using the value_counts() method to count the number of times each value of a particular column occurs:**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gladiator                                4\n",
      "We're the Millers                        4\n",
      "Lo imposible                             4\n",
      "Project X                                4\n",
      "The Wolf of Wall Street                  4\n",
      "                                        ..\n",
      "The Holiday                              4\n",
      "The Fast and the Furious: Tokyo Drift    4\n",
      "Crank                                    4\n",
      "Perfume: The Story of a Murderer         4\n",
      "Murder Mystery                           4\n",
      "Name: movie, Length: 904, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "movie = movies.movie # selecting the movie column of the movies dataframe.\n",
    "print(movie.value_counts())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Using the corr() method to find the relationship between numerical variables in a dataframe**\n",
    "The dataframe `corr()` method returns the correlation between all quantitative features in the dataframe as a dataframe as shown below:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Unnamed: 0      year      imdb  metascore     votes     gross  \\\n",
      "Unnamed: 0    1.000000  0.998707  0.008577   0.092386 -0.036715  0.190007   \n",
      "year          0.998707  1.000000  0.014492   0.096722 -0.028082  0.196261   \n",
      "imdb          0.008577  0.014492  1.000000   0.699024  0.513588  0.032634   \n",
      "metascore     0.092386  0.096722  0.699024   1.000000  0.324337  0.070391   \n",
      "votes        -0.036715 -0.028082  0.513588   0.324337  1.000000  0.443705   \n",
      "gross         0.190007  0.196261  0.032634   0.070391  0.443705  1.000000   \n",
      "n_imdb        0.008577  0.014492  1.000000   0.699024  0.513588  0.032634   \n",
      "\n",
      "              n_imdb  \n",
      "Unnamed: 0  0.008577  \n",
      "year        0.014492  \n",
      "imdb        1.000000  \n",
      "metascore   0.699024  \n",
      "votes       0.513588  \n",
      "gross       0.032634  \n",
      "n_imdb      1.000000  \n"
     ]
    }
   ],
   "source": [
    "correlation = movies.corr()\n",
    "print(correlation)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As is expected, each column has a correlation of 1 with itself.\n",
    "Another thing worth taking note of is that `imdb` seems to have a strong positive correlation with `metascore` (ie. 0.699024). This means that the higher the metascore of a movie, the higher its imdb rating."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Removing duplicate observations from data frame\n",
    "The **drop_duplicates()** method is used to remove duplicate rows from our dataframe.\n",
    "Since no duplicates exist in our data frame, we will create a new data frame consisting of our movies data frame concatenated with itself, which will therefore contain a duplicate entry for each entry in the movies data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "copy = pd.concat([movies, movies])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will use the shape attribute to confirm that the copy data frame contains twice as many observations as the movies data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rows in movies: 3616\n",
      "No. of rows in copy: 7232\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of rows in movies:\",movies.shape[0])\n",
    "print(\"No. of rows in copy:\",copy.shape[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will use the drop_duplicates() method to remove duplicate entries from our copy data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "copy.drop_duplicates(inplace=True, keep=\"first\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The **inplace** argument specifies that we want to remove the duplicates from the data frame on which the method was called rather than return a copy of that data frame with the duplicates removed.\n",
    "The **keep** argument also specifies in this case that we want to keep the first occurrence of the duplicate and remove all other occurrences."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To confirm that all duplicates have been removed from our copy data frame, we will again use the shape method and compare number of rows of copy with number of rows of movies."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rows in movies: 3616\n",
      "No. of rows in copy: 3616\n",
      "Voila\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of rows in movies:\",movies.shape[0])\n",
    "print(\"No. of rows in copy:\",copy.shape[0])\n",
    "print(\"Voila\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modifying column labels of the data frame.\n",
    "The **columns** attribute returns an iterable of all the column labels in a data frame and can likewise be used to modify column labels."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Displaying all column labels of the movies data frame:**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'movie', 'year', 'imdb', 'metascore', 'votes', 'genre',\n",
      "       'runtime', 'gross', 'n_imdb'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "columns = movies.columns\n",
    "print(columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Changing all column labels of data frame via lists**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------before-modification----------\n",
      "Index(['Unnamed: 0', 'movie', 'year', 'imdb', 'metascore', 'votes', 'genre',\n",
      "       'runtime', 'gross', 'n_imdb'],\n",
      "      dtype='object')\n",
      "----------after-modification-----------\n",
      "Index(['', 'new_movie', 'new_year', 'new_imdb', 'new_metascore', 'new_votes',\n",
      "       'new_genre', 'new_runtime', 'new_gross', 'new_n_imdb'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "copy = movies.copy() # Creating a copy of movies so we can use the original column labels later\n",
    "new_columns = [\"\", \"new_movie\", \"new_year\", \"new_imdb\", \"new_metascore\", \"new_votes\", \"new_genre\", \"new_runtime\", \"new_gross\", \"new_n_imdb\"]\n",
    "print(\"----------before-modification----------\")\n",
    "print(copy.columns)\n",
    "\n",
    "copy.columns = new_columns\n",
    "print(\"----------after-modification-----------\")\n",
    "print(copy.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Changing all column labels of dataframe via list comprehensions**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----before-alteration------\n",
      "Index(['', 'new_movie', 'new_year', 'new_imdb', 'new_metascore', 'new_votes',\n",
      "       'new_genre', 'new_runtime', 'new_gross', 'new_n_imdb'],\n",
      "      dtype='object')\n",
      "-----after-alternation------\n",
      "Index(['', 'movie', 'year', 'imdb', 'metascore', 'votes', 'genre', 'runtime',\n",
      "       'gross', 'n_imdb'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"-----before-alteration------\")\n",
    "print(copy.columns)\n",
    "\n",
    "copy.columns = [column[4:] for column in copy.columns]\n",
    "print(\"-----after-alternation------\")\n",
    "print(copy.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Changing all column labels of dataframe using rename method:**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----before-modification-----\n",
      "Index(['', 'movie', 'year', 'imdb', 'metascore', 'votes', 'genre', 'runtime',\n",
      "       'gross', 'n_imdb'],\n",
      "      dtype='object')\n",
      "-----after-modification-----\n",
      "Index(['ID', 'movie', 'year', 'imdb', 'metascore', 'votes', 'genre', 'runtime',\n",
      "       'gross', 'n_imdb'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"-----before-modification-----\")\n",
    "print(copy.columns)\n",
    "\n",
    "copy.rename(columns={\"\":\"ID\"}, inplace=True) # Changes empty string label of first column to \"ID\"\n",
    "\n",
    "print(\"-----after-modification-----\")\n",
    "print(copy.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Identifying and fixing missing values in dataframe\n",
    "Sometimes some data points may be missing for certain observations in our dataset.\n",
    "Such data points are said to be null, and the following code snippets show how to deal with such cases in pandas."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Detecting missing values in a data frame:**\n",
    "The `isnull()` method returns a dataframe frame with all cells replaced with boolean values. Cells with a value of null are replaced with `True`, and cells with a value other than null are replaced with `False`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  movie   year   imdb  metascore  votes  genre  runtime  \\\n",
      "0          False  False  False  False      False  False  False    False   \n",
      "1          False  False  False  False      False  False  False    False   \n",
      "2          False  False  False  False      False  False  False    False   \n",
      "3          False  False  False  False      False  False  False    False   \n",
      "4          False  False  False  False      False  False  False    False   \n",
      "...          ...    ...    ...    ...        ...    ...    ...      ...   \n",
      "3611       False  False  False  False      False  False  False    False   \n",
      "3612       False  False  False  False      False  False  False    False   \n",
      "3613       False  False  False  False      False  False  False    False   \n",
      "3614       False  False  False  False      False  False  False    False   \n",
      "3615       False  False  False  False      False  False  False    False   \n",
      "\n",
      "      gross  n_imdb  \n",
      "0     False   False  \n",
      "1     False   False  \n",
      "2     False   False  \n",
      "3     False   False  \n",
      "4     False   False  \n",
      "...     ...     ...  \n",
      "3611   True   False  \n",
      "3612  False   False  \n",
      "3613  False   False  \n",
      "3614  False   False  \n",
      "3615   True   False  \n",
      "\n",
      "[3616 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "null_frame = movies.isnull()\n",
    "print(null_frame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The above result means that the cell on row `3615` and column `\"gross\"` is null."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Identifying columns with missing values in a dataframe**\n",
    "The `sum()` dataframe method sums up all values in each column whose values are summable and returns a data series of all the resulting sums.\n",
    "Each value in the data series is indexed with the label of the column whose values they are the sum of."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `sum()` method can be used in conjunction with the `isnull()` method to identify all columns with missing values as shown below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are the columns in the movies dataframe with missing values and the number of missing values for each column:\n",
      "Unnamed: 0     0\n",
      "movie          0\n",
      "year           0\n",
      "imdb           0\n",
      "metascore      0\n",
      "votes          0\n",
      "genre          0\n",
      "runtime        0\n",
      "gross         80\n",
      "n_imdb         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_columns = movies.isnull().sum()\n",
    "print(\"The following are the columns in the movies dataframe with missing values and the number of missing values for each column:\")\n",
    "print(null_columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the above results, it's safe to say that the gross column has 80 missing values whereas all other columns have no missing values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Removing all rows with missing or null values**\n",
    "The **dropna()** method is used to remove all rows in a dataframe with missing values as shown below:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rows before deletion: 3616\n",
      "No. of rows after deletion: 3536\n"
     ]
    }
   ],
   "source": [
    "copy = movies.copy() # Creating a copy of the movies data frame.\n",
    "print(\"No. of rows before deletion:\", copy.shape[0])\n",
    "copy.dropna(inplace=True)\n",
    "print(\"No. of rows after deletion:\", copy.shape[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the above results, we can notice that the 80 rows that contained null values were deleted from the dataframe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Removing all columns with missing or null values**\n",
    "The **dropna()** method can also be used to remove columns from a dataframe whose cells contain null values.\n",
    "To accomplish this, the `axis` argument of the `dropna()` method is set to `1` as shown below:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns before removal:\n",
      " Index(['Unnamed: 0', 'movie', 'year', 'imdb', 'metascore', 'votes', 'genre',\n",
      "       'runtime', 'gross', 'n_imdb'],\n",
      "      dtype='object')\n",
      "Columns after removal:\n",
      " Index(['Unnamed: 0', 'movie', 'year', 'imdb', 'metascore', 'votes', 'genre',\n",
      "       'runtime', 'n_imdb'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "copy = movies.copy() # Creating a copy of the movies data frame.\n",
    "print(\"Columns before removal:\\n\", copy.columns)\n",
    "copy.dropna(inplace=True, axis=1)\n",
    "print(\"Columns after removal:\\n\", copy.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice that the `gross` column, which was the only column containing missing values, has been removed from our dataframe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Replacing all missing values in a dataframe**\n",
    "Imputation refers to the replacement of missing values in a dataframe with other values as opposed to deleting them.\n",
    "The **fillna()** method is used for imputation in pandas."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `fillna()` method replaces all cells in the dataframe that have missing values with a specified value.\n",
    "In the code snippet below we replace all the missing values in a copy of the `movies` dataframe with the mean of the values in the gross column:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------before-imputation------\n",
      "Unnamed: 0     0\n",
      "movie          0\n",
      "year           0\n",
      "imdb           0\n",
      "metascore      0\n",
      "votes          0\n",
      "genre          0\n",
      "runtime        0\n",
      "gross         80\n",
      "n_imdb         0\n",
      "dtype: int64\n",
      "------after-imputation-------\n",
      "Unnamed: 0    0\n",
      "movie         0\n",
      "year          0\n",
      "imdb          0\n",
      "metascore     0\n",
      "votes         0\n",
      "genre         0\n",
      "runtime       0\n",
      "gross         0\n",
      "n_imdb        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "copy = movies.copy() # Creating a copy of the movies dataframe.\n",
    "average = copy.gross.mean()\n",
    "print(\"------before-imputation------\")\n",
    "print(copy.isnull().sum())\n",
    "\n",
    "# Replacing null values with average\n",
    "copy.fillna(average, inplace=True)\n",
    "print(\"------after-imputation-------\")\n",
    "print(copy.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that after imputation, all null values in the `gross` column were replaced with the `average`, and the `gross` column therefore no longer has missing values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DataFrame slicing, selecting, extracting\n",
    "In extracting data from a dataframe, a data scientist's goal is usually one of the following:\n",
    "   - Extracting a single cell\n",
    "   - Extracting a single column\n",
    "   - Extracting a single row\n",
    "   - Extracting multiple columns\n",
    "   - Extracting multiple rows\n",
    "\n",
    "With the above actions, one can extract any piece of data they require from a dataframe, be it a single value, an entire row, an entire column, a small grid wtihin the dataframe, etc."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Requirements for extracting data from a dataframe\n",
    "Python provides three useful tools for extracting data from your dataframe:\n",
    "1. The index operator `[]`\n",
    "2. The loc dataframe attribute `.loc`\n",
    "3. The iloc dataframe attribute `.iloc`\n",
    "\n",
    "In addition to this, every dataframe has **row labels** and **column labels**, which must be used in conjunction with the above 3 tools in order to extract data from a dataframe.\n",
    "\n",
    "There are 2 kinds of row and column labels in the dataframe:\n",
    " 1. The actual label\n",
    " 2. The integer-location-based label\n",
    "\n",
    "The **actual labels** refer to the real labels of the rows and columns that come with the dataframe.\n",
    " - These labels may be strings, integers, or any other data type.\n",
    " - In the `movies` dataframe for instance, the actual column labels include `\"movie\"`, `\"genre\"`, `\"rating\"`, etc., which are all strings.\n",
    "  - The actual row labels are the integers from `0` to `3616`, but they can actually be of any datatype.\n",
    "    - Dataframes must always have row and column labels, and when a dataframe you create or read does not have row labels for instance, pandas automatically assigns integer labels to the dataframe which is the case with our movies dataframe.\n",
    "\n",
    "The **integer-location-based labels** are unreal labels pandas assigns to each row and column based on its position in the dataframe.\n",
    " - The first row or column is given an integer-location-based label of `0` due to its position as the first row/column in the dataframe.\n",
    " - The next column or row is given an integer-location based label of `1`, and so on and so forth.\n",
    " - These unreal labels will always be integers, and are different from the actual labels on the dataframe which may be any data type.\n",
    "\n",
    "The movies dataframe is printed below for reference."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0                                       movie  year  imdb  \\\n",
      "0              0                                   Gladiator  2000   8.5   \n",
      "1              1                                     Memento  2000   8.4   \n",
      "2              2                                      Snatch  2000   8.3   \n",
      "3              3                         Requiem for a Dream  2000   8.3   \n",
      "4              4                                       X-Men  2000   7.4   \n",
      "...          ...                                         ...   ...   ...   \n",
      "3611        3611                             Triple Frontier  2019   6.4   \n",
      "3612        3612  How to Train Your Dragon: The Hidden World  2019   7.5   \n",
      "3613        3613                 Men in Black: International  2019   5.6   \n",
      "3614        3614                      Zombieland: Double Tap  2019   6.8   \n",
      "3615        3615                              Murder Mystery  2019   6.0   \n",
      "\n",
      "      metascore    votes                                   genre  runtime  \\\n",
      "0            67  1265139      ['Action', ' Adventure', ' Drama']  155 min   \n",
      "1            80  1065249                ['Mystery', ' Thriller']  113 min   \n",
      "2            55   744029                    ['Comedy', ' Crime']  104 min   \n",
      "3            68   725875                               ['Drama']  102 min   \n",
      "4            64   550968     ['Action', ' Adventure', ' Sci-Fi']  104 min   \n",
      "...         ...      ...                                     ...      ...   \n",
      "3611         61    90756      ['Action', ' Adventure', ' Crime']  125 min   \n",
      "3612         71    87006  ['Animation', ' Action', ' Adventure']  104 min   \n",
      "3613         38    85672     ['Action', ' Adventure', ' Comedy']  114 min   \n",
      "3614         55    82913        ['Action', ' Comedy', ' Horror']   99 min   \n",
      "3615         38    81450         ['Action', ' Comedy', ' Crime']   97 min   \n",
      "\n",
      "            gross  n_imdb  \n",
      "0     187705427.0    85.0  \n",
      "1      25544867.0    84.0  \n",
      "2      30328156.0    83.0  \n",
      "3       3635482.0    83.0  \n",
      "4     157299717.0    74.0  \n",
      "...           ...     ...  \n",
      "3611          NaN    64.0  \n",
      "3612  160799505.0    75.0  \n",
      "3613   79800736.0    56.0  \n",
      "3614   26803104.0    68.0  \n",
      "3615          NaN    60.0  \n",
      "\n",
      "[3616 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(movies)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that the actual row labels for the `movies` dataframe are integers.\n",
    "\n",
    "To make it easier to understand the difference between actual labels of a dataframe and integer-location based labels, we will use the values in the `movie` column as the new row labels via the `set_index()` method as shown below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Unnamed: 0  year  imdb  metascore  \\\n",
      "movie                                                                           \n",
      "Gladiator                                            0  2000   8.5         67   \n",
      "Memento                                              1  2000   8.4         80   \n",
      "Snatch                                               2  2000   8.3         55   \n",
      "Requiem for a Dream                                  3  2000   8.3         68   \n",
      "X-Men                                                4  2000   7.4         64   \n",
      "...                                                ...   ...   ...        ...   \n",
      "Triple Frontier                                   3611  2019   6.4         61   \n",
      "How to Train Your Dragon: The Hidden World        3612  2019   7.5         71   \n",
      "Men in Black: International                       3613  2019   5.6         38   \n",
      "Zombieland: Double Tap                            3614  2019   6.8         55   \n",
      "Murder Mystery                                    3615  2019   6.0         38   \n",
      "\n",
      "                                              votes  \\\n",
      "movie                                                 \n",
      "Gladiator                                   1265139   \n",
      "Memento                                     1065249   \n",
      "Snatch                                       744029   \n",
      "Requiem for a Dream                          725875   \n",
      "X-Men                                        550968   \n",
      "...                                             ...   \n",
      "Triple Frontier                               90756   \n",
      "How to Train Your Dragon: The Hidden World    87006   \n",
      "Men in Black: International                   85672   \n",
      "Zombieland: Double Tap                        82913   \n",
      "Murder Mystery                                81450   \n",
      "\n",
      "                                                                             genre  \\\n",
      "movie                                                                                \n",
      "Gladiator                                       ['Action', ' Adventure', ' Drama']   \n",
      "Memento                                                   ['Mystery', ' Thriller']   \n",
      "Snatch                                                        ['Comedy', ' Crime']   \n",
      "Requiem for a Dream                                                      ['Drama']   \n",
      "X-Men                                          ['Action', ' Adventure', ' Sci-Fi']   \n",
      "...                                                                            ...   \n",
      "Triple Frontier                                 ['Action', ' Adventure', ' Crime']   \n",
      "How to Train Your Dragon: The Hidden World  ['Animation', ' Action', ' Adventure']   \n",
      "Men in Black: International                    ['Action', ' Adventure', ' Comedy']   \n",
      "Zombieland: Double Tap                            ['Action', ' Comedy', ' Horror']   \n",
      "Murder Mystery                                     ['Action', ' Comedy', ' Crime']   \n",
      "\n",
      "                                            runtime        gross  n_imdb  \n",
      "movie                                                                     \n",
      "Gladiator                                   155 min  187705427.0    85.0  \n",
      "Memento                                     113 min   25544867.0    84.0  \n",
      "Snatch                                      104 min   30328156.0    83.0  \n",
      "Requiem for a Dream                         102 min    3635482.0    83.0  \n",
      "X-Men                                       104 min  157299717.0    74.0  \n",
      "...                                             ...          ...     ...  \n",
      "Triple Frontier                             125 min          NaN    64.0  \n",
      "How to Train Your Dragon: The Hidden World  104 min  160799505.0    75.0  \n",
      "Men in Black: International                 114 min   79800736.0    56.0  \n",
      "Zombieland: Double Tap                       99 min   26803104.0    68.0  \n",
      "Murder Mystery                               97 min          NaN    60.0  \n",
      "\n",
      "[3616 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "copy = movies.copy() # Copying movies dataframe\n",
    "\n",
    "copy.set_index(\"movie\", inplace=True) # Using the movie column as row labels.\n",
    "print(copy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extracting data from a dataframe without loc and iloc\n",
    "The following snippets demonstrate how we can select single cells, single rows, single columns, and multiple rows and columns from our dataframe without using the loc and iloc attributes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Using the index operator to extract a single cell from your dataframe**\n",
    "A cell in a dataframe is an intersection of a row and a column.\n",
    "To extract a single cell in the dataframe, you need the row label and column label for the row and column on which the cell lies respectively.\n",
    "> dataframe[column_label][row_label]\n",
    "\n",
    "The code cell below selects the cell located at the intersection of the `genre` column and `Gladiator`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "selection = copy[\"genre\"][\"Gladiator\"]\n",
    "print(\"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Indexing a dataframe\n",
    "Slice indexing re\n",
    "There are two types of indexing:\n",
    " - Slice indexing\n",
    " - Positional Indexing\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Gladiator'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [77]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhead\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mGladiator\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgenre\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m)\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(copy\u001B[38;5;241m.\u001B[39mhead()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenre\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGladiator\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\intro-to-data-science\\lib\\site-packages\\pandas\\core\\indexing.py:960\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    958\u001B[0m     key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(com\u001B[38;5;241m.\u001B[39mapply_if_callable(x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m key)\n\u001B[0;32m    959\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_scalar_access(key):\n\u001B[1;32m--> 960\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_value\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtakeable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_takeable\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    961\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_tuple(key)\n\u001B[0;32m    962\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    963\u001B[0m     \u001B[38;5;66;03m# we by definition only have the 0th axis\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\intro-to-data-science\\lib\\site-packages\\pandas\\core\\frame.py:3622\u001B[0m, in \u001B[0;36mDataFrame._get_value\u001B[1;34m(self, index, col, takeable)\u001B[0m\n\u001B[0;32m   3616\u001B[0m engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39m_engine\n\u001B[0;32m   3618\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex, MultiIndex):\n\u001B[0;32m   3619\u001B[0m     \u001B[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001B[39;00m\n\u001B[0;32m   3620\u001B[0m     \u001B[38;5;66;03m#  results if our categories are integers that dont match our codes\u001B[39;00m\n\u001B[0;32m   3621\u001B[0m     \u001B[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001B[39;00m\n\u001B[1;32m-> 3622\u001B[0m     row \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m series\u001B[38;5;241m.\u001B[39m_values[row]\n\u001B[0;32m   3625\u001B[0m \u001B[38;5;66;03m# For MultiIndex going through engine effectively restricts us to\u001B[39;00m\n\u001B[0;32m   3626\u001B[0m \u001B[38;5;66;03m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\intro-to-data-science\\lib\\site-packages\\pandas\\core\\indexes\\range.py:389\u001B[0m, in \u001B[0;36mRangeIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m    387\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m    388\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n\u001B[1;32m--> 389\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n\u001B[0;32m    390\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mget_loc(key, method\u001B[38;5;241m=\u001B[39mmethod, tolerance\u001B[38;5;241m=\u001B[39mtolerance)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'Gladiator'"
     ]
    }
   ],
   "source": [
    "print(copy.head().loc[\"Gladiator\", \"genre\"])\n",
    "print(copy.head()[\"genre\"][\"Gladiator\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Without loc and iloc pandas attributes.\n",
    "# Introduce the loc and iloc pandas attributes. The loc and iloc pandas attributes allow you to select rows and columns by label. The loc uses the specific row and column labels where as the iloc uses integer arguments it assigns to each row and to each column."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
