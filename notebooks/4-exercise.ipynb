{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 2\n",
    "**Name**: Francis O'Hara Aidoo\n",
    "**Roll Number**: 10201100101 <br>\n",
    "\n",
    "Task: Solve all practice questions from the following webpages:\n",
    "\n",
    "1.https://pythonbasics.org/pandas-dataframe/\n",
    "\n",
    "1.1 https://data36.com/pandas-tutorial-1-basics-reading-data-files-dataframes-data-selection/\n",
    "\n",
    "2.https://www.tutorialspoint.com/python_pandas/python_pandas_dataframe.htm\n",
    "3.https://www.learndatasci.com/tutorials/python-pandas-tutorial-complete-introduction-for-beginners/   (different sources)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Website 1 Solutions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Creating n x 1 Dataframe from List\n",
    "The following code creates an n x 1 dataframe from a list containing n elements."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0\n",
      "0       Banana\n",
      "1        Apple\n",
      "2        Guava\n",
      "3  Straw berry\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fruits = [\"Banana\", \"Apple\", \"Guava\", \"Straw berry\"]\n",
    "fruits_df = pd.DataFrame(fruits)\n",
    "\n",
    "print(fruits_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating m x n Dataframe from List\n",
    "The following code creates an m x n dataframe from a list of m lists each of length n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Name  Score Grade\n",
      "0   Anna Tetteh     88    B2\n",
      "1  Eugene Stark     54    D7\n",
      "2    Helen Troy    100   A1+\n",
      "3  Bruce Banner     92    A1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "grades = [[\"Anna Tetteh\", 88, \"B2\"], [\"Eugene Stark\", 54, \"D7\"], [\"Helen Troy\", 100, \"A1+\"], [\"Bruce Banner\", 92, \"A1\"]]\n",
    "column_labels = [\"Name\", \"Score\", \"Grade\"]\n",
    "grades_df = pd.DataFrame(grades, columns=column_labels)\n",
    "print(grades_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Selecting column from a DataFrame by column name\n",
    "The following code selects the Name column from the grades_df DataFrame we created in the previous cell."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Anna Tetteh\n",
      "1    Eugene Stark\n",
      "2      Helen Troy\n",
      "3    Bruce Banner\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "names = grades_df[\"Name\"]\n",
    "print(names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Adding columns to an existing DataFrame\n",
    "The following code adds a column from a newly created DataFrame to an existing DataFrame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Before-Addition------------------\n",
      "           Name  Score Grade\n",
      "0   Anna Tetteh     88    B2\n",
      "1  Eugene Stark     54    D7\n",
      "2    Helen Troy    100   A1+\n",
      "3  Bruce Banner     92    A1\n",
      "-----------------After-Addition-------------------\n",
      "           Name  Score Grade                  Course\n",
      "0   Anna Tetteh     88    B2  Information Technology\n",
      "1  Eugene Stark     54    D7        Computer Science\n",
      "2    Helen Troy    100   A1+    Computer Engineering\n",
      "3  Bruce Banner     92    A1                Business\n"
     ]
    }
   ],
   "source": [
    "# Grades_df before addition of DataFrame\n",
    "print(\"----------------Before-Addition------------------\")\n",
    "print(grades_df)\n",
    "\n",
    "courses_df = pd.DataFrame([\"Information Technology\", \"Computer Science\", \"Computer Engineering\", \"Business\"], columns=[\"Course\"]) # New DataFrame\n",
    "grades_df[\"Course\"] = courses_df[\"Course\"]\n",
    "\n",
    "# Grades_df after addition of DataFrame\n",
    "print(\"-----------------After-Addition-------------------\")\n",
    "print(grades_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deleting columns\n",
    "The following code snippet deletes the Course column from grades_df using the <em>del</em> Python keyword"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Before-Deletion-------------------\n",
      "           Name  Score Grade                  Course\n",
      "0   Anna Tetteh     88    B2  Information Technology\n",
      "1  Eugene Stark     54    D7        Computer Science\n",
      "2    Helen Troy    100   A1+    Computer Engineering\n",
      "3  Bruce Banner     92    A1                Business\n",
      "-----------------After-Deletion-------------------\n",
      "           Name  Score Grade\n",
      "0   Anna Tetteh     88    B2\n",
      "1  Eugene Stark     54    D7\n",
      "2    Helen Troy    100   A1+\n",
      "3  Bruce Banner     92    A1\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------Before-Deletion-------------------\")\n",
    "print(grades_df)\n",
    "del grades_df[\"Course\"]\n",
    "print(\"-----------------After-Deletion-------------------\")\n",
    "print(grades_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Selecting single rows from data frame using .loc method\n",
    "The following code snippet selects the third row from the grades_df data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name     Helen Troy\n",
      "Score           100\n",
      "Grade           A1+\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "row3 = grades_df.loc[2]\n",
    "print(row3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Selecting single rows from data frame using .iloc method\n",
    "The following code snippet selects the 2nd row from the grades_df data frame using the .iloc data frame method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name     Eugene Stark\n",
      "Score              54\n",
      "Grade              D7\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "row2 = grades_df.iloc[1]\n",
    "print(row2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Appending rows to a data frame\n",
    "The following code snippet appends rows from a new ddta frame into the grades_df data frame using pd.concat() method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Before-Append-------------------\n",
      "           Name  Score Grade\n",
      "0   Anna Tetteh     88    B2\n",
      "1  Eugene Stark     54    D7\n",
      "2    Helen Troy    100   A1+\n",
      "3  Bruce Banner     92    A1\n",
      "-----------------After-Append-------------------\n",
      "               Name  Score Grade\n",
      "0       Anna Tetteh     88    B2\n",
      "1      Eugene Stark     54    D7\n",
      "2        Helen Troy    100   A1+\n",
      "3      Bruce Banner     92    A1\n",
      "4  Bertholdt Hoover     87    C3\n",
      "5      Armin Arlelt    100  A1++\n",
      "6      Pieck Finger     95    A1\n"
     ]
    }
   ],
   "source": [
    "new_df = pd.DataFrame([[\"Bertholdt Hoover\", 87, \"C3\"], [\"Armin Arlelt\", 100, \"A1++\"], [\"Pieck Finger\", 95, \"A1\"]], columns=[\"Name\", \"Score\", \"Grade\"])\n",
    "\n",
    "print(\"-----------------Before-Append-------------------\")\n",
    "print(grades_df)\n",
    "grades_df = pd.concat((grades_df, new_df), ignore_index=True)\n",
    "\n",
    "print(\"-----------------After-Append-------------------\")\n",
    "print(grades_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deleting single rows from a data frame\n",
    "The following code snippet deletes a single row from the data frame using the .drop() data frame method"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Before-deletion-------------------\n",
      "               Name  Score Grade\n",
      "0       Anna Tetteh     88    B2\n",
      "1      Eugene Stark     54    D7\n",
      "2        Helen Troy    100   A1+\n",
      "3      Bruce Banner     92    A1\n",
      "4  Bertholdt Hoover     87    C3\n",
      "5      Armin Arlelt    100  A1++\n",
      "6      Pieck Finger     95    A1\n",
      "-----------------After-deletion-------------------\n",
      "               Name  Score Grade\n",
      "0       Anna Tetteh     88    B2\n",
      "2        Helen Troy    100   A1+\n",
      "3      Bruce Banner     92    A1\n",
      "4  Bertholdt Hoover     87    C3\n",
      "5      Armin Arlelt    100  A1++\n",
      "6      Pieck Finger     95    A1\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------Before-deletion-------------------\")\n",
    "print(grades_df)\n",
    "\n",
    "grades_df = grades_df.drop(1)\n",
    "\n",
    "print(\"-----------------After-deletion-------------------\")\n",
    "print(grades_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a data frame from a dictionary\n",
    "The following code snippet creates a data frame from a python dictionary."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID   first_name   last_name     team      country\n",
      "0  001      Michael      Asante    Alpha       Canada\n",
      "1  002      Gabriel          Io    Bravo          USA\n",
      "2  003  Evangelista    Neptunes  Charlie      Namibia\n",
      "3  004      Hillary          Yu    Delta  Philippines\n",
      "4  005        Sarah  Pennyworth     Echo    Greenland\n"
     ]
    }
   ],
   "source": [
    "dictionary = {\"ID\":[\"001\", \"002\", \"003\", \"004\", \"005\"], \"first_name\":[\"Michael\", \"Gabriel\", \"Evangelista\", \"Hillary\", \"Sarah\"], \"last_name\":[\"Asante\", \"Io\", \"Neptunes\", \"Yu\", \"Pennyworth\"], \"team\":[\"Alpha\", \"Bravo\", \"Charlie\", \"Delta\", \"Echo\"], \"country\":[\"Canada\", \"USA\", \"Namibia\", \"Philippines\", \"Greenland\"]}\n",
    "\n",
    "soldiers = pd.DataFrame(dictionary)\n",
    "\n",
    "print(soldiers)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a data frame from a numpy array\n",
    "The following code snippet defines a numpy array and instantiates a pandas data frame from it:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID   first_name   last_name     team      country\n",
      "0  001      Michael      Asante    Alpha      Country\n",
      "1  002      Gabriel          Io    Bravo          USA\n",
      "2  003  Evangelista    Neptunes  Charlie      Namibia\n",
      "3  004      Hillary          Yu    Delta  Philippines\n",
      "4  005        Sarah  Pennyworth     Echo    Greenland\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "numpy_array = np.array([[\"001\", \"Michael\", \"Asante\", \"Alpha\", \"Country\"], [\"002\", \"Gabriel\", \"Io\", \"Bravo\", \"USA\"], [\"003\", \"Evangelista\", \"Neptunes\", \"Charlie\", \"Namibia\"], [\"004\", \"Hillary\", \"Yu\", \"Delta\", \"Philippines\"], [\"005\", \"Sarah\", \"Pennyworth\", \"Echo\", \"Greenland\"]])\n",
    "\n",
    "new_df2 = pd.DataFrame(numpy_array, columns=[\"ID\", \"first_name\", \"last_name\", \"team\", \"country\"])\n",
    "\n",
    "print(new_df2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a data frame from an existing data frame\n",
    "The following code snippet copies an existing data frame to create a new data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID   first_name   last_name     team      country\n",
      "0  001      Michael      Asante    Alpha      Country\n",
      "1  002      Gabriel          Io    Bravo          USA\n",
      "2  003  Evangelista    Neptunes  Charlie      Namibia\n",
      "3  004      Hillary          Yu    Delta  Philippines\n",
      "4  005        Sarah  Pennyworth     Echo    Greenland\n"
     ]
    }
   ],
   "source": [
    "new_df3 = new_df2.copy()\n",
    "print(new_df3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a data frame from a csv file\n",
    "The following code snippet creates a data frame by importing data from a csv file:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  first_name   last_name      team  country\n",
      "0   0      Gideon      Asante       Red    Ghana\n",
      "1   1      Dmitri   Dvocovich      Blue   Russia\n",
      "2   2    Francois    Arouette     Green   France\n",
      "3   3     Bradley      Cooper    Purple      USA\n",
      "4   4      Kratos      Athens   Crimson   Greece\n"
     ]
    }
   ],
   "source": [
    "new_df4 = pd.read_csv(\"C://users/franc/PycharmProjects/intro-to-data-science/data/data.csv\")\n",
    "print(new_df4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Website 2 Solutions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reading data from a csv file into a data frame in Pandas.\n",
    "The following code snippet reads data from a .csv file into a pandas data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id          item   price\n",
      "0   1         Apple    2.50\n",
      "1   2        Banana    4.50\n",
      "2   3   Straw Berry   10.00\n",
      "3   4     Pineapple    3.75\n",
      "4   5        Orange    8.00\n",
      "5   6       Coconut    7.50\n",
      "6   7         Mango   10.00\n",
      "7   8         Guava    7.50\n",
      "8   9         Grape    1.50\n"
     ]
    }
   ],
   "source": [
    "fruits = pd.read_csv(\"C://users/franc/PycharmProjects/intro-to-data-science/data/fruits.csv\", delimiter=\",\")\n",
    "print(fruits)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Website 2 Solutions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reading Data from a CSV file into a pandas data frame.\n",
    "The following code snippet reads data from a CSV file specified by the url into a pandas data frame and stores the result in the <em>data</em> variable."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2018-01-01 00:01:01  read  country_7  2458151261      SEO  North America\n",
      "0     2018-01-01 00:03:20  read  country_7  2458151262      SEO  South America\n",
      "1     2018-01-01 00:04:01  read  country_7  2458151263  AdWords         Africa\n",
      "2     2018-01-01 00:04:02  read  country_7  2458151264  AdWords         Europe\n",
      "3     2018-01-01 00:05:03  read  country_8  2458151265   Reddit  North America\n",
      "4     2018-01-01 00:05:42  read  country_6  2458151266   Reddit  North America\n",
      "...                   ...   ...        ...         ...      ...            ...\n",
      "1789  2018-01-01 23:57:14  read  country_2  2458153051  AdWords  North America\n",
      "1790  2018-01-01 23:58:33  read  country_8  2458153052      SEO           Asia\n",
      "1791  2018-01-01 23:59:36  read  country_6  2458153053   Reddit           Asia\n",
      "1792  2018-01-01 23:59:36  read  country_7  2458153054  AdWords         Europe\n",
      "1793  2018-01-01 23:59:38  read  country_5  2458153055   Reddit           Asia\n",
      "\n",
      "[1794 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"http://46.101.230.157/dilan/pandas_tutorial_read.csv\", delimiter=\";\")\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the above code snippet, no column labels are included in the csv file. The code snippet below reads the csv file and includes the appropriate column labels as an argument to the pd.read_csv() method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              my_datetime event    country     user_id   source          topic\n",
      "0     2018-01-01 00:01:01  read  country_7  2458151261      SEO  North America\n",
      "1     2018-01-01 00:03:20  read  country_7  2458151262      SEO  South America\n",
      "2     2018-01-01 00:04:01  read  country_7  2458151263  AdWords         Africa\n",
      "3     2018-01-01 00:04:02  read  country_7  2458151264  AdWords         Europe\n",
      "4     2018-01-01 00:05:03  read  country_8  2458151265   Reddit  North America\n",
      "...                   ...   ...        ...         ...      ...            ...\n",
      "1790  2018-01-01 23:57:14  read  country_2  2458153051  AdWords  North America\n",
      "1791  2018-01-01 23:58:33  read  country_8  2458153052      SEO           Asia\n",
      "1792  2018-01-01 23:59:36  read  country_6  2458153053   Reddit           Asia\n",
      "1793  2018-01-01 23:59:36  read  country_7  2458153054  AdWords         Europe\n",
      "1794  2018-01-01 23:59:38  read  country_5  2458153055   Reddit           Asia\n",
      "\n",
      "[1795 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"http://46.101.230.157/dilan/pandas_tutorial_read.csv\", delimiter=\";\", names=['my_datetime', 'event', 'country', 'user_id', 'source', 'topic'])\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Displaying a sample of your data frame.\n",
    "The following code snippet uses the head() data frame method to display the first 10 observations in the data set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           my_datetime event    country     user_id   source          topic\n",
      "0  2018-01-01 00:01:01  read  country_7  2458151261      SEO  North America\n",
      "1  2018-01-01 00:03:20  read  country_7  2458151262      SEO  South America\n",
      "2  2018-01-01 00:04:01  read  country_7  2458151263  AdWords         Africa\n",
      "3  2018-01-01 00:04:02  read  country_7  2458151264  AdWords         Europe\n",
      "4  2018-01-01 00:05:03  read  country_8  2458151265   Reddit  North America\n",
      "5  2018-01-01 00:05:42  read  country_6  2458151266   Reddit  North America\n",
      "6  2018-01-01 00:06:06  read  country_2  2458151267   Reddit         Europe\n",
      "7  2018-01-01 00:06:15  read  country_6  2458151268  AdWords         Europe\n",
      "8  2018-01-01 00:07:21  read  country_7  2458151269  AdWords  North America\n",
      "9  2018-01-01 00:07:29  read  country_5  2458151270   Reddit  North America\n"
     ]
    }
   ],
   "source": [
    "print(data.head(10))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet uses the tail() data frame method to display the last 10 observations in the data set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              my_datetime event    country     user_id   source          topic\n",
      "1785  2018-01-01 23:54:26  read  country_2  2458153046  AdWords         Africa\n",
      "1786  2018-01-01 23:54:39  read  country_6  2458153047   Reddit           Asia\n",
      "1787  2018-01-01 23:54:45  read  country_2  2458153048   Reddit           Asia\n",
      "1788  2018-01-01 23:55:04  read  country_7  2458153049  AdWords         Europe\n",
      "1789  2018-01-01 23:56:42  read  country_4  2458153050  AdWords           Asia\n",
      "1790  2018-01-01 23:57:14  read  country_2  2458153051  AdWords  North America\n",
      "1791  2018-01-01 23:58:33  read  country_8  2458153052      SEO           Asia\n",
      "1792  2018-01-01 23:59:36  read  country_6  2458153053   Reddit           Asia\n",
      "1793  2018-01-01 23:59:36  read  country_7  2458153054  AdWords         Europe\n",
      "1794  2018-01-01 23:59:38  read  country_5  2458153055   Reddit           Asia\n"
     ]
    }
   ],
   "source": [
    "print(data.tail(10))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet on the other hand displays 10 random observations from our data set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              my_datetime event    country     user_id   source          topic\n",
      "1645  2018-01-01 22:10:47  read  country_7  2458152906  AdWords         Europe\n",
      "523   2018-01-01 07:04:09  read  country_7  2458151784   Reddit  North America\n",
      "1320  2018-01-01 17:58:22  read  country_2  2458152581   Reddit           Asia\n",
      "1562  2018-01-01 21:11:16  read  country_8  2458152823   Reddit           Asia\n",
      "327   2018-01-01 04:20:59  read  country_5  2458151588   Reddit         Europe\n",
      "1738  2018-01-01 23:22:29  read  country_2  2458152999   Reddit           Asia\n",
      "246   2018-01-01 03:25:09  read  country_2  2458151507  AdWords         Europe\n",
      "1008  2018-01-01 13:35:49  read  country_7  2458152269   Reddit  South America\n",
      "1785  2018-01-01 23:54:26  read  country_2  2458153046  AdWords         Africa\n",
      "1019  2018-01-01 13:43:06  read  country_2  2458152280  AdWords           Asia\n"
     ]
    }
   ],
   "source": [
    "print(data.sample(10))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Selecting Specific columns from the data frame\n",
    "The following code snippet selects specific features from our data set using square bracket notation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        country          topic\n",
      "0     country_7  North America\n",
      "1     country_7  South America\n",
      "2     country_7         Africa\n",
      "3     country_7         Europe\n",
      "4     country_8  North America\n",
      "...         ...            ...\n",
      "1790  country_2  North America\n",
      "1791  country_8           Asia\n",
      "1792  country_6           Asia\n",
      "1793  country_7         Europe\n",
      "1794  country_5           Asia\n",
      "\n",
      "[1795 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Selecting the country and topic columns only.\n",
    "sub_data = data[[\"country\", \"topic\"]]\n",
    "print(sub_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet selects a single feature from our data set using dot notation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       country_7\n",
      "1       country_7\n",
      "2       country_7\n",
      "3       country_7\n",
      "4       country_8\n",
      "          ...    \n",
      "1790    country_2\n",
      "1791    country_8\n",
      "1792    country_6\n",
      "1793    country_7\n",
      "1794    country_5\n",
      "Name: country, Length: 1795, dtype: object\n"
     ]
    }
   ],
   "source": [
    "sub_data = data.country\n",
    "print(sub_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Filtering specific observations from the data frame\n",
    "The following code snippet filters the data frame, selecting only those data frames where the source feature has a value of SEO."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              my_datetime event    country     user_id source          topic\n",
      "0     2018-01-01 00:01:01  read  country_7  2458151261    SEO  North America\n",
      "1     2018-01-01 00:03:20  read  country_7  2458151262    SEO  South America\n",
      "11    2018-01-01 00:08:57  read  country_7  2458151272    SEO      Australia\n",
      "15    2018-01-01 00:11:22  read  country_7  2458151276    SEO  North America\n",
      "16    2018-01-01 00:13:05  read  country_8  2458151277    SEO  North America\n",
      "...                   ...   ...        ...         ...    ...            ...\n",
      "1772  2018-01-01 23:45:58  read  country_7  2458153033    SEO  South America\n",
      "1777  2018-01-01 23:49:52  read  country_5  2458153038    SEO  North America\n",
      "1779  2018-01-01 23:51:25  read  country_4  2458153040    SEO  South America\n",
      "1784  2018-01-01 23:54:03  read  country_2  2458153045    SEO  North America\n",
      "1791  2018-01-01 23:58:33  read  country_8  2458153052    SEO           Asia\n",
      "\n",
      "[346 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "sub_data = data[data.source==\"SEO\"]\n",
    "print(sub_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combining Pandas methods and operators\n",
    "The following code snippet selects the first five observations using the head() method, and selects only the country and source features using the square bracket syntax."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     country   source\n",
      "0  country_7      SEO\n",
      "1  country_7      SEO\n",
      "2  country_7  AdWords\n",
      "3  country_7  AdWords\n",
      "4  country_8   Reddit\n"
     ]
    }
   ],
   "source": [
    "sub_data = data.head(5)[[\"country\", \"source\"]]\n",
    "print(sub_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet selects the country and source features from the data set first and then selects the first five observations using the head() method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     country   source\n",
      "0  country_7      SEO\n",
      "1  country_7      SEO\n",
      "2  country_7  AdWords\n",
      "3  country_7  AdWords\n",
      "4  country_8   Reddit\n"
     ]
    }
   ],
   "source": [
    "sub_data = data[[\"country\", \"source\"]].head(5)\n",
    "print(sub_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pandas Tutorial Challenge\n",
    "Select the user_id, the country and the topic columns for the users who are from country_2! Print the first five rows only!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id    country   topic\n",
      "6   2458151267  country_2  Europe\n",
      "13  2458151274  country_2  Europe\n",
      "17  2458151278  country_2    Asia\n",
      "19  2458151280  country_2    Asia\n",
      "20  2458151281  country_2    Asia\n"
     ]
    }
   ],
   "source": [
    "sub_data = data[data.country==\"country_2\"][[\"user_id\", \"country\", \"topic\"]].head()\n",
    "print(sub_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Website 3 Solutions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating an empty pandas data frame\n",
    "The following code snippet creates an empty data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a data frame from a list\n",
    "The following code snippet creates a one-dimensional data frame from a list."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name\n",
      "0     Google\n",
      "1  Bloomberg\n",
      "2       Meta\n",
      "3      Apple\n",
      "4      Tesla\n"
     ]
    }
   ],
   "source": [
    "data = [\"Google\", \"Bloomberg\", \"Meta\", \"Apple\", \"Tesla\"] # the list\n",
    "df = pd.DataFrame(data, columns=[\"name\"])\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet creates a multidimensional data frame from a list of lists."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name    market cap\n",
      "0     Google  1.270000e+12\n",
      "1  Bloomberg  1.230000e+11\n",
      "2       Meta  3.429000e+11\n",
      "3      Apple  2.230000e+12\n",
      "4      Tesla  6.499900e+11\n"
     ]
    }
   ],
   "source": [
    "data = [[\"Google\", 1.27e12], [\"Bloomberg\", 123e9], [\"Meta\", 342.9e9], [\"Apple\", 2.23e12], [\"Tesla\", 649.99e9]] # the list\n",
    "df = pd.DataFrame(data, columns=[\"name\", \"market cap\"])\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet creates a multidimensional data frame from a list of dictionaries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name    market cap\n",
      "0     Google  1.270000e+12\n",
      "1  Bloomberg  1.230000e+09\n",
      "2       Meta  3.429000e+11\n",
      "3      Apple  2.230000e+12\n",
      "4      Tesla  6.499900e+11\n"
     ]
    }
   ],
   "source": [
    "data = [{\"name\": \"Google\",\"market cap\": 1.27e12}, {\"name\":\"Bloomberg\", \"market cap\": 1.23e9}, {\"name\":\"Meta\", \"market cap\":3.429e11}, {\"name\": \"Apple\", \"market cap\": 2.23e12}, {\"name\": \"Tesla\", \"market cap\": 6.4999e11}]\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a data frame from a dictionary\n",
    "The following code snippet creates a data frame from a dictionary.\n",
    "NB: The keys of the dictionary become feature labels and the values become observations for the corresponding feature."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Age\n",
      "0    Tom   28\n",
      "1   Jack   34\n",
      "2  Steve   29\n",
      "3  Ricky   42\n"
     ]
    }
   ],
   "source": [
    "data = {'Name':['Tom', 'Jack', 'Steve', 'Ricky'],'Age':[28,34,29,42]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the above snippet, the rows of the data frame are numbered from 0 to n-1 by default, where n is the numbber of observations in the data frame.\n",
    "In the code snippet below, the index argument of the data frame constructor will be used to label the rows."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age\n",
      "A1    Tom   28\n",
      "A2   Jack   34\n",
      "A3  Steve   29\n",
      "A4  Ricky   42\n"
     ]
    }
   ],
   "source": [
    "data = {'Name':['Tom', 'Jack', 'Steve', 'Ricky'],'Age':[28,34,29,42]}\n",
    "df = pd.DataFrame(data, index=[\"A1\", \"A2\", \"A3\", \"A4\"])\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet creates a dataframe from a dictionary of pandas series."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name    market_cap\n",
      "0     Google  1.270000e+12\n",
      "1  Bloomberg  1.230000e+09\n",
      "2       Meta  3.429000e+11\n",
      "3      Apple  2.230000e+12\n",
      "4      Tesla  6.499900e+11\n"
     ]
    }
   ],
   "source": [
    "names = pd.Series([\"Google\", \"Bloomberg\", \"Meta\", \"Apple\", \"Tesla\"])\n",
    "market_caps = pd.Series([1.27e12, 1.23e9, 3.429e11, 2.23e12, 6.4999e11])\n",
    "data = {\"name\": names, \"market_cap\": market_caps}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Adding columns to a data frame\n",
    "The following code snippet adds a column to the df dataframe from a newly created data series."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name    market_cap  year_founded\n",
      "0     Google  1.270000e+12          1998\n",
      "1  Bloomberg  1.230000e+09          1981\n",
      "2       Meta  3.429000e+11          2004\n",
      "3      Apple  2.230000e+12          1976\n",
      "4      Tesla  6.499900e+11          2003\n"
     ]
    }
   ],
   "source": [
    "new_series = pd.Series([1998, 1981, 2004, 1976, 2003])\n",
    "df[\"year_founded\"] = new_series\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet adds a column to the df column from an existing data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name    market_cap  year_founded  random_factor\n",
      "0     Google  1.270000e+12          1998   6.356356e+08\n",
      "1  Bloomberg  1.230000e+09          1981   6.208985e+05\n",
      "2       Meta  3.429000e+11          2004   1.711078e+08\n",
      "3      Apple  2.230000e+12          1976   1.128543e+09\n",
      "4      Tesla  6.499900e+11          2003   3.245082e+08\n"
     ]
    }
   ],
   "source": [
    "df2 = df\n",
    "df[\"random_factor\"] = df[\"market_cap\"] / df[\"year_founded\"]\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deleting columns from a data frame\n",
    "The following code snippet deletes a column from the data frame using the del python keyword."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------before-deletion--------\n",
      "        name    market_cap  year_founded  random_factor\n",
      "0     Google  1.270000e+12          1998   6.356356e+08\n",
      "1  Bloomberg  1.230000e+09          1981   6.208985e+05\n",
      "2       Meta  3.429000e+11          2004   1.711078e+08\n",
      "3      Apple  2.230000e+12          1976   1.128543e+09\n",
      "4      Tesla  6.499900e+11          2003   3.245082e+08\n",
      "--------after-deletion---------\n",
      "        name    market_cap  year_founded\n",
      "0     Google  1.270000e+12          1998\n",
      "1  Bloomberg  1.230000e+09          1981\n",
      "2       Meta  3.429000e+11          2004\n",
      "3      Apple  2.230000e+12          1976\n",
      "4      Tesla  6.499900e+11          2003\n"
     ]
    }
   ],
   "source": [
    "print(\"-------before-deletion--------\")\n",
    "print(df)\n",
    "\n",
    "# deletion\n",
    "copy = df[\"random_factor\"] # creating a copy of column to be deleted.\n",
    "\n",
    "del df[\"random_factor\"]\n",
    "\n",
    "print(\"--------after-deletion---------\")\n",
    "print(df)\n",
    "df[\"random_factor\"] = copy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet deletes a column from the data frame using the data frame pop() method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------before-deletion--------\n",
      "        name    market_cap  year_founded  random_factor\n",
      "0     Google  1.270000e+12          1998   6.356356e+08\n",
      "1  Bloomberg  1.230000e+09          1981   6.208985e+05\n",
      "2       Meta  3.429000e+11          2004   1.711078e+08\n",
      "3      Apple  2.230000e+12          1976   1.128543e+09\n",
      "4      Tesla  6.499900e+11          2003   3.245082e+08\n",
      "--------after-deletion---------\n",
      "        name    market_cap  year_founded\n",
      "0     Google  1.270000e+12          1998\n",
      "1  Bloomberg  1.230000e+09          1981\n",
      "2       Meta  3.429000e+11          2004\n",
      "3      Apple  2.230000e+12          1976\n",
      "4      Tesla  6.499900e+11          2003\n"
     ]
    }
   ],
   "source": [
    "print(\"-------before-deletion--------\")\n",
    "print(df)\n",
    "\n",
    "df.pop(\"random_factor\")\n",
    "\n",
    "print(\"--------after-deletion---------\")\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Selecting rows and columns from a data frame with loc\n",
    "The following code snippets selects the name and year_founded columns as well as the 0th, 2nd, and 4th row from the df data frame using loc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name  year_founded\n",
      "0  Google          1998\n",
      "2    Meta          2004\n",
      "4   Tesla          2003\n"
     ]
    }
   ],
   "source": [
    "selection = df.loc[[0,2,4], [\"name\", \"year_founded\"]]\n",
    "print(selection)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet performs the above selection using iloc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name  year_founded\n",
      "0  Google          1998\n",
      "2    Meta          2004\n",
      "4   Tesla          2003\n"
     ]
    }
   ],
   "source": [
    "selection = df.iloc[[0, 2, 4], [0, 2]]\n",
    "print(selection)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet selects a range of rows and columns from the df data frame using slicing.\n",
    "NB: For iloc, stop index of the slice is exclusive, but for loc, both start and stop index of the slice are inclusive."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     market_cap  year_founded\n",
      "0  1.270000e+12          1998\n",
      "1  1.230000e+09          1981\n"
     ]
    }
   ],
   "source": [
    "selection = df.iloc[0:2, 1:3]\n",
    "print(selection)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deleting rows from a data frame\n",
    "Just as columns are deleted from a data frame using the del keyword and .pop method, Rows can be deleted using the del keyword and the .drop method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet deletes the 3rd column from the df data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Before-deletion---------\n",
      "        name    market_cap  year_founded\n",
      "0     Google  1.270000e+12          1998\n",
      "1  Bloomberg  1.230000e+09          1981\n",
      "2       Meta  3.429000e+11          2004\n",
      "3      Apple  2.230000e+12          1976\n",
      "4      Tesla  6.499900e+11          2003\n",
      "---------After-deletion--------\n",
      "        name    market_cap  year_founded\n",
      "0     Google  1.270000e+12          1998\n",
      "1  Bloomberg  1.230000e+09          1981\n",
      "3      Apple  2.230000e+12          1976\n",
      "4      Tesla  6.499900e+11          2003\n"
     ]
    }
   ],
   "source": [
    "print(\"--------Before-deletion---------\")\n",
    "print(df)\n",
    "\n",
    "df = df.drop(2)\n",
    "\n",
    "print(\"---------After-deletion--------\")\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Website 4 Solutions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a data frame from scratch (using a dictionary)\n",
    "The following code snippet creates a pandas data frame from scratch using the below dictionary."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   apples  oranges\n",
      "0       3        0\n",
      "1       2        3\n",
      "2       0        7\n",
      "3       1        2\n"
     ]
    }
   ],
   "source": [
    "data = {'apples': [3, 2, 0, 1], 'oranges': [0, 3, 7, 2]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet does the above, but includes row labels for the data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        apples  oranges\n",
      "June         3        0\n",
      "Robert       2        3\n",
      "Lily         0        7\n",
      "David        1        2\n"
     ]
    }
   ],
   "source": [
    "data = {'apples': [3, 2, 0, 1], 'oranges': [0, 3, 7, 2]}\n",
    "df = pd.DataFrame(data,index=[\"June\", \"Robert\", \"Lily\", \"David\"])\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the above data frame, each row represents a particular customer's order.\n",
    "### Selecting a single row\n",
    "In the code snippet below, a single row(custmer) is selected via the iloc method and row label."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apples     3\n",
      "oranges    0\n",
      "Name: June, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "selection = df.loc[\"June\"]\n",
    "print(selection)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reading data from a csv file\n",
    "The following code snippet demonstrates how to use the read_csv method to read csv files into a pandas data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        apples  oranges\n",
      "June         3        0\n",
      "Robert       2        3\n",
      "Lily         0        7\n",
      "David        1        2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"c://users/franc/PycharmProjects/intro-to-data-science/data/purchases.csv\", delimiter=\",\", index_col=0)\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reading data from a json file\n",
    "The following code snippet reads the purchases data from a json file instead via the read_json method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           apples  oranges\n",
      "0   David       3        0\n",
      "1    June       2        3\n",
      "2    Lily       0        7\n",
      "3  Robert       1        2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"C:/users/franc/PycharmProjects/intro-to-data-science/data/purchases.json\")\n",
    "print(df)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reading data from an sql database.\n",
    "Pandas can read tables stored inside a relational database and store them as data frames.\n",
    "The following code snippets demonstrates how to read data into a pandas data frame from an sql database. <br>\n",
    "For the purposes of this tutorial, we'll be making use of the sqlite database which stores databases as a single file with the extension .db from which we can read data similar to how we would read data from a csv file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We first need to install <strong>pysqlite3</strong> which is a database driver that allows python programs to interact with sqlite databases using the following command:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pysqlite3\n",
      "  Downloading pysqlite3-0.4.7.tar.gz (40 kB)\n",
      "     -------------------------------------- 40.1/40.1 kB 383.2 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: pysqlite3\n",
      "  Building wheel for pysqlite3 (setup.py): started\n",
      "  Building wheel for pysqlite3 (setup.py): finished with status 'done'\n",
      "  Running setup.py clean for pysqlite3\n",
      "Failed to build pysqlite3\n",
      "Installing collected packages: pysqlite3\n",
      "  Running setup.py install for pysqlite3: started\n",
      "  Running setup.py install for pysqlite3: finished with status 'done'\n",
      "Successfully installed pysqlite3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Legacy build of wheel for 'pysqlite3' created no files.\n",
      "  Command arguments: 'C:\\Users\\franc\\anaconda3\\envs\\intro-to-data-science\\python.exe' -u -c '\n",
      "  exec(compile('\"'\"''\"'\"''\"'\"'\n",
      "  # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py\n",
      "  #\n",
      "  # - It imports setuptools before invoking setup.py, to enable projects that directly\n",
      "  #   import from `distutils.core` to work with newer packaging standards.\n",
      "  # - It provides a clear error message when setuptools is not installed.\n",
      "  # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so\n",
      "  #   setuptools doesn'\"'\"'t think the script is `-c`. This avoids the following warning:\n",
      "  #     manifest_maker: standard file '\"'\"'-c'\"'\"' not found\".\n",
      "  # - It generates a shim setup.py, for handling setup.cfg-only projects.\n",
      "  import os, sys, tokenize\n",
      "  \n",
      "  try:\n",
      "      import setuptools\n",
      "  except ImportError as error:\n",
      "      print(\n",
      "          \"ERROR: Can not execute `setup.py` since setuptools is not available in \"\n",
      "          \"the build environment.\",\n",
      "          file=sys.stderr,\n",
      "      )\n",
      "      sys.exit(1)\n",
      "  \n",
      "  __file__ = %r\n",
      "  sys.argv[0] = __file__\n",
      "  \n",
      "  if os.path.exists(__file__):\n",
      "      filename = __file__\n",
      "      with tokenize.open(__file__) as f:\n",
      "          setup_py_code = f.read()\n",
      "  else:\n",
      "      filename = \"<auto-generated setuptools caller>\"\n",
      "      setup_py_code = \"from setuptools import setup; setup()\"\n",
      "  \n",
      "  exec(compile(setup_py_code, filename, \"exec\"))\n",
      "  '\"'\"''\"'\"''\"'\"' % ('\"'\"'C:\\\\Users\\\\franc\\\\AppData\\\\Local\\\\Temp\\\\pip-install-g_r3rkmr\\\\pysqlite3_72c2f381f87d4b779d564779f9525b26\\\\setup.py'\"'\"',), \"<pip-setuptools-caller>\", \"exec\"))' bdist_wheel -d 'C:\\Users\\franc\\AppData\\Local\\Temp\\pip-wheel-4vke6jyn'\n",
      "  Command output: [use --verbose to show]\n"
     ]
    }
   ],
   "source": [
    "!pip install pysqlite3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we have to create a connection to our sqlite database using the connect method of the sqlite3 driver."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "connection = sqlite3.connect(\"C:/users/franc/PycharmProjects/intro-to-data-science/data/data.db\")\n",
    "# connection is now a database connection object we can use to access data stored in the data.db database."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following command uses the read_sql_query() method to query the data.db database through our connection object, and read the resulting table as a pandas data frame which we store in the variable df."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index  apples  oranges\n",
      "0    June       3        0\n",
      "1  Robert       2        3\n",
      "2    Lily       0        7\n",
      "3   David       1        2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM purchases\", connection)\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We failed to state that the index column of the purchases table in our data.db database was to be treated as the index column. <br>\n",
    "But all hope is not lost as we can use the set_index() data frame method to set our index column."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        apples  oranges\n",
      "index                  \n",
      "June         3        0\n",
      "Robert       2        3\n",
      "Lily         0        7\n",
      "David        1        2\n"
     ]
    }
   ],
   "source": [
    "df = df.set_index(\"index\")\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Converting a pandas data frame into other formats.\n",
    "The following code snippet converts the df data frame into a **csv file** stored in the <em>output</em> sub-directory of our <em>data</em> directory."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/output/output_csv.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet converts the df data frame into a **json file** and stores it in the <em>output</em> sub-directory of the <em>data</em> directory."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "df.to_json(\"../data/output/output_json.json\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code snippet converts the df data frame into an **sql table** and stores it in the data.db sqlite database via our connection object."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql(\"new purchases\", connection)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The following section covers some important data frame operations\n",
    "To demonstrate various operations that can be performed on a pandas database, we will be using a [movies data set](https://storage.googleapis.com/kagglesdsdata/datasets/516826/954748/df_movie_ratings.csv?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20221015%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20221015T113249Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=2736f429dbdfa2c10167ce36777a57e8f2874890ca7396cae864f32bdde4b06a2e1f872cec927266e26740a615c87eea111bb4e6f771c2b2d440bcdf6e22548ddafb32754312dd011087dafc8eb5bca0ecff86b3752e3b834498ba96327548216bf36d9d3a29e4243d95d3052c5abe1436b41027d40ab7743ae73f539b620b32473ddd71dd4e3f3e9a93e86b1fc24a02286786f8004719a68e0fb720b0d76b0c1194d21b241d91e96ae5eb345c9d4393b3a98a5742754d6a6739349a994d4cfb59a51dc308e10c9f6ebd2a9123968af54150de38e149c2318b9a9226607c003f2a7bcdc9f30cc1b4e98c0083f5c84f54e8663bbdcf1e80d672d60ff737a49c53) we downloaded from kaggle."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0                                       movie  year  imdb  \\\n",
      "0              0                                   Gladiator  2000   8.5   \n",
      "1              1                                     Memento  2000   8.4   \n",
      "2              2                                      Snatch  2000   8.3   \n",
      "3              3                         Requiem for a Dream  2000   8.3   \n",
      "4              4                                       X-Men  2000   7.4   \n",
      "...          ...                                         ...   ...   ...   \n",
      "3611        3611                             Triple Frontier  2019   6.4   \n",
      "3612        3612  How to Train Your Dragon: The Hidden World  2019   7.5   \n",
      "3613        3613                 Men in Black: International  2019   5.6   \n",
      "3614        3614                      Zombieland: Double Tap  2019   6.8   \n",
      "3615        3615                              Murder Mystery  2019   6.0   \n",
      "\n",
      "      metascore    votes                                   genre  runtime  \\\n",
      "0            67  1265139      ['Action', ' Adventure', ' Drama']  155 min   \n",
      "1            80  1065249                ['Mystery', ' Thriller']  113 min   \n",
      "2            55   744029                    ['Comedy', ' Crime']  104 min   \n",
      "3            68   725875                               ['Drama']  102 min   \n",
      "4            64   550968     ['Action', ' Adventure', ' Sci-Fi']  104 min   \n",
      "...         ...      ...                                     ...      ...   \n",
      "3611         61    90756      ['Action', ' Adventure', ' Crime']  125 min   \n",
      "3612         71    87006  ['Animation', ' Action', ' Adventure']  104 min   \n",
      "3613         38    85672     ['Action', ' Adventure', ' Comedy']  114 min   \n",
      "3614         55    82913        ['Action', ' Comedy', ' Horror']   99 min   \n",
      "3615         38    81450         ['Action', ' Comedy', ' Crime']   97 min   \n",
      "\n",
      "            gross  n_imdb  \n",
      "0     187705427.0    85.0  \n",
      "1      25544867.0    84.0  \n",
      "2      30328156.0    83.0  \n",
      "3       3635482.0    83.0  \n",
      "4     157299717.0    74.0  \n",
      "...           ...     ...  \n",
      "3611          NaN    64.0  \n",
      "3612  160799505.0    75.0  \n",
      "3613   79800736.0    56.0  \n",
      "3614   26803104.0    68.0  \n",
      "3615          NaN    60.0  \n",
      "\n",
      "[3616 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# importing the movies data set from a csv file\n",
    "movies= pd.read_csv(\"../data/df_movie_ratings.csv\", delimiter=\",\")\n",
    "print(movies)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Viewing the data\n",
    "The following snippets cover various data frame methods that may be useful for viewing or analyzing the data stored in the data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Using the head() method to view first few observations in data frame**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                   movie  year  imdb  metascore    votes  \\\n",
      "0           0               Gladiator  2000   8.5         67  1265139   \n",
      "1           1                 Memento  2000   8.4         80  1065249   \n",
      "2           2                  Snatch  2000   8.3         55   744029   \n",
      "3           3     Requiem for a Dream  2000   8.3         68   725875   \n",
      "4           4                   X-Men  2000   7.4         64   550968   \n",
      "5           5               Cast Away  2000   7.8         73   491129   \n",
      "6           6         American Psycho  2000   7.6         64   453294   \n",
      "7           7             Unbreakable  2000   7.3         62   370098   \n",
      "8           8  Mission: Impossible II  2000   6.1         59   299974   \n",
      "9           9        Meet the Parents  2000   7.0         73   299610   \n",
      "\n",
      "                                   genre  runtime        gross  n_imdb  \n",
      "0     ['Action', ' Adventure', ' Drama']  155 min  187705427.0    85.0  \n",
      "1               ['Mystery', ' Thriller']  113 min   25544867.0    84.0  \n",
      "2                   ['Comedy', ' Crime']  104 min   30328156.0    83.0  \n",
      "3                              ['Drama']  102 min    3635482.0    83.0  \n",
      "4    ['Action', ' Adventure', ' Sci-Fi']  104 min  157299717.0    74.0  \n",
      "5    ['Adventure', ' Drama', ' Romance']  143 min  233632142.0    78.0  \n",
      "6         ['Comedy', ' Crime', ' Drama']  101 min   15070285.0    76.0  \n",
      "7       ['Drama', ' Mystery', ' Sci-Fi']  106 min   95011339.0    73.0  \n",
      "8  ['Action', ' Adventure', ' Thriller']  123 min  215409889.0    61.0  \n",
      "9                 ['Comedy', ' Romance']  108 min  166244045.0    70.0  \n"
     ]
    }
   ],
   "source": [
    "data = movies.head(10) # Selects first 10 observations in data frame.\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
